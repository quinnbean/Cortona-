
        // ============================================================
        // INITIALIZATION
        // ============================================================
        
        const socket = io();
        let recognition = null;
        let isListening = false;
        let isRestarting = false; // Flag to prevent UI flicker during mic restart
        let currentDevice = null;
        let devices = {};
        let activityLog = [];
        let alwaysListen = false;
        let continuousMode = false;
        let autoType = true;
        let spellCheckEnabled = true;
        let sensitivity = 3; // 1-5, higher = more strict matching
        let isActiveDictation = false; // true when wake word triggered dictation
        
        // Whisper mode - now uses OpenAI cloud API for better accuracy
        let useWhisper = false;
        let useCloudWhisper = true;  // Use OpenAI cloud Whisper (fast, accurate)
        let whisperRecorder = null;
        let whisperMediaStream = null;
        const WHISPER_LOCAL_URL = 'http://localhost:5051';  // Fallback local
        
        // TTS state
        let ttsEnabled = true;
        let ttsVoice = 'nova';  // Options: alloy, echo, fable, onyx, nova, shimmer
        let currentTTSAudio = null;
        
        // Transcript history
        let transcriptHistory = [];
        const sessionStartTime = new Date();
        
        // Session & context tracking for adaptive AI
        const sessionId = 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
        let lastAction = null;  // Track last action for "do that again" / "repeat"
        let lastTargetApp = null;  // Track last app for context
        let conversationContext = [];  // Local conversation history for display
        
        // Sensitivity labels
        const sensitivityLabels = {
            1: 'Very Low',
            2: 'Low', 
            3: 'Medium',
            4: 'High',
            5: 'Exact'
        };
        
        // Check browser support
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let micPermission = 'prompt'; // 'granted', 'denied', or 'prompt'
        
        // Electron API detection
        const isElectron = window.electronAPI?.isElectron || false;
        
        if (isElectron) {
            console.log('üñ•Ô∏è Running in Electron app');
            
            // Listen for global shortcut activation
            window.electronAPI.onActivateVoice(() => {
                console.log('üé§ Activated via global shortcut');
                if (!isListening) {
                    toggleListening();
                }
                // Focus the mic and show we're ready
                document.getElementById('mic-button').focus();
                addActivity('üé§ Activated via ‚åò+Shift+J', 'success');
            });
            
            // Listen for quick recording
            window.electronAPI.onStartRecording(() => {
                console.log('üé§ Quick recording started');
                if (!isListening) {
                    toggleListening();
                }
            });
            
            // Push-to-Talk: stop recording when key released
            if (window.electronAPI.onStopRecording) {
                window.electronAPI.onStopRecording(() => {
                    console.log('üé§ Push-to-talk released');
                    if (isListening) {
                        stopListening();
                    }
                });
            }
        }
        
        // ELECTRON: Always use Whisper, skip Web Speech API entirely
        if (isElectron) {
            console.log('[ELECTRON] Using OpenAI Cloud Whisper for speech recognition');
            useWhisper = true;  // Force Whisper mode
            useCloudWhisper = true;  // Use cloud API (faster, more accurate)
            checkMicPermission();
            // Don't initialize Web Speech API at all in Electron
        } else if (!SpeechRecognition) {
            document.getElementById('browser-warning').style.display = 'flex';
            document.getElementById('mic-button').classList.add('disabled');
        } else {
            initSpeechRecognition();
            checkMicPermission();
        }
        
        // Check and track microphone permission status
        async function checkMicPermission() {
            // If running in Electron, use native macOS permission check
            if (window.electronAPI?.isElectron) {
                try {
                    const status = await window.electronAPI.getMicStatus();
                    console.log('[MIC] Electron mic status:', status);
                    
                    if (status === 'not-determined') {
                        // Request permission
                        const granted = await window.electronAPI.requestMicPermission();
                        micPermission = granted ? 'granted' : 'denied';
                        console.log('[MIC] Permission request result:', granted);
                    } else if (status === 'denied') {
                        micPermission = 'denied';
                        addActivity('‚ùå Microphone blocked. Open System Preferences > Security & Privacy > Privacy > Microphone and enable Cortona.', 'warning');
                    } else {
                        micPermission = status;
                    }
                    updateMicPermissionUI();
                    return;
                } catch (e) {
                    console.log('[MIC] Electron permission check failed:', e);
                }
            }
            
            // Browser-based permission check
            try {
                const result = await navigator.permissions.query({ name: 'microphone' });
                micPermission = result.state;
                updateMicPermissionUI();
                
                // Listen for permission changes
                result.onchange = () => {
                    micPermission = result.state;
                    updateMicPermissionUI();
                    if (result.state === 'granted') {
                        addActivity('üé§ Microphone access granted!', 'success');
                    }
                };
            } catch (e) {
                // Permissions API not supported, we'll find out when we try to use it
                console.log('Permissions API not available');
            }
        }
        
        function updateMicPermissionUI() {
            const micButton = document.getElementById('mic-button');
            const warning = document.getElementById('browser-warning');
            
            if (micPermission === 'denied') {
                warning.innerHTML = '‚ö†Ô∏è Microphone access blocked. <a href="#" onclick="showPermissionHelp()" style="color: var(--accent); text-decoration: underline;">Click here to fix</a>';
                warning.style.display = 'flex';
            } else if (micPermission === 'granted') {
                warning.style.display = 'none';
            }
        }
        
        function showPermissionHelp() {
            alert('To enable microphone access:' + String.fromCharCode(10,10) + '1. Click the lock icon in Chrome address bar' + String.fromCharCode(10) + '2. Find Microphone and set it to Allow' + String.fromCharCode(10) + '3. Refresh the page' + String.fromCharCode(10,10) + 'Or go to: chrome://settings/content/microphone');
        }
        
        // Request microphone permission explicitly
        async function requestMicPermission() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                // Permission granted! Stop the stream immediately (we just needed permission)
                stream.getTracks().forEach(track => track.stop());
                micPermission = 'granted';
                updateMicPermissionUI();
                addActivity('üé§ Microphone access granted!', 'success');
                return true;
            } catch (err) {
                if (err.name === 'NotAllowedError') {
                    micPermission = 'denied';
                    updateMicPermissionUI();
                    addActivity('‚ö†Ô∏è Microphone access denied. Click the lock icon in the address bar to allow.', 'warning');
                } else {
                    addActivity('‚ö†Ô∏è Could not access microphone: ' + err.message, 'warning');
                }
                return false;
            }
        }
        
        // Auto-detect device info based on browser/OS - ALWAYS runs on every load
        function getDeviceInfo() {
            const ua = navigator.userAgent;
            const platform = navigator.platform;
            
            let name, icon, wakeWord;
            
            if (platform.includes('Mac') || ua.includes('Macintosh')) {
                name = 'MacBook';
                icon = 'üíª';
                wakeWord = 'mac';
            } else if (platform.includes('Win') || ua.includes('Windows')) {
                name = 'Windows PC';
                icon = 'üñ•Ô∏è';
                wakeWord = 'windows';
            } else if (ua.includes('iPhone')) {
                name = 'iPhone';
                icon = 'üì±';
                wakeWord = 'phone';
            } else if (ua.includes('iPad')) {
                name = 'iPad';
                icon = 'üì±';
                wakeWord = 'ipad';
            } else if (ua.includes('Android')) {
                name = 'Android';
                icon = 'üì±';
                wakeWord = 'android';
            } else if (platform.includes('Linux')) {
                name = 'Linux PC';
                icon = 'üêß';
                wakeWord = 'linux';
            } else {
                name = 'My Device';
                icon = 'üíª';
                wakeWord = 'computer';
            }
            
            return { name, icon, wakeWord };
        }
        
        // Auto-detect device info on EVERY page load
        const deviceInfo = getDeviceInfo();
        
        // Use device type as stable ID (so Mac is always "macbook", Windows is always "windows_pc")
        const deviceId = deviceInfo.name.toLowerCase().replace(/\\s+/g, '_');
        
        // Load ALL saved settings (including name, wakeWord, icon that may have been edited remotely)
        let savedPrefs = {};
        try {
            const saved = localStorage.getItem('voicehub_prefs');
            if (saved) savedPrefs = JSON.parse(saved);
        } catch (e) {}
        
        // Use saved name/wakeWord/icon if they exist, otherwise use auto-detected
        // This allows remote edits to persist
        currentDevice = {
            id: deviceId,
            name: savedPrefs.name || deviceInfo.name,
            wakeWord: savedPrefs.wakeWord || deviceInfo.wakeWord,
            icon: savedPrefs.icon || deviceInfo.icon,
            language: savedPrefs.language || 'en-US',
            wordsTyped: savedPrefs.wordsTyped || 0,
            sessions: savedPrefs.sessions || 0,
            alwaysListen: savedPrefs.alwaysListen || false,
            continuous: savedPrefs.continuous || false,
            autoType: savedPrefs.autoType !== false,
            spellCheck: savedPrefs.spellCheck !== false,
            sensitivity: savedPrefs.sensitivity || 3
        };
        
        // Put in devices list
        devices[deviceId] = currentDevice;
        
        function saveDevices() {
            // Save ALL device settings including name, wakeWord, icon
            localStorage.setItem('voicehub_prefs', JSON.stringify({
                name: currentDevice.name,
                wakeWord: currentDevice.wakeWord,
                icon: currentDevice.icon,
                language: currentDevice.language,
                wordsTyped: currentDevice.wordsTyped,
                sessions: currentDevice.sessions,
                alwaysListen: currentDevice.alwaysListen,
                continuous: currentDevice.continuous,
                autoType: currentDevice.autoType,
                spellCheck: currentDevice.spellCheck,
                sensitivity: currentDevice.sensitivity
            }));
        }
        
        console.log('=== DEVICE INIT ===');
        console.log('Saved prefs from localStorage:', savedPrefs);
        console.log('Auto-detected:', deviceInfo);
        console.log('Final device:', currentDevice.name, '| Wake word:', currentDevice.wakeWord);
        console.log('==================');
        
        // Save immediately to ensure prefs are persisted
        // (This also writes back any existing prefs to ensure they're not lost)
        saveDevices();
        
        alwaysListen = currentDevice.alwaysListen || false;
        sensitivity = currentDevice.sensitivity || 3;
        
        // ============================================================
        // COMMAND PARSING & ROUTING
        // ============================================================
        
        // Known AI apps and targets
        const knownApps = {
            'cursor': { name: 'Cursor', icon: 'üñ±Ô∏è', keywords: ['cursor', 'code editor'] },
            'claude': { name: 'Claude', icon: 'üß†', keywords: ['claude', 'anthropic'] },
            'chatgpt': { name: 'ChatGPT', icon: 'üí¨', keywords: ['chatgpt', 'chat gpt', 'openai', 'gpt'] },
            'copilot': { name: 'Copilot', icon: '‚ú®', keywords: ['copilot', 'github copilot'] },
            'gemini': { name: 'Gemini', icon: 'üåü', keywords: ['gemini', 'google ai', 'bard'] },
            'terminal': { name: 'Terminal', icon: '‚¨õ', keywords: ['terminal', 'command line', 'shell', 'console'] },
            'browser': { name: 'Browser', icon: 'üåê', keywords: ['browser', 'chrome', 'firefox', 'safari', 'edge'] },
            'notes': { name: 'Notes', icon: 'üìù', keywords: ['notes', 'notepad', 'text editor'] },
            'slack': { name: 'Slack', icon: 'üíº', keywords: ['slack'] },
            'discord': { name: 'Discord', icon: 'üéÆ', keywords: ['discord'] },
        };
        
        // Parse a command to extract target device/app and the actual command
        function parseCommand(text) {
            // Trim whitespace - speech recognition often adds leading/trailing spaces
            text = text.trim();
            
            // Fix common speech recognition mishearings
            // "right" at the start of a command is often "write"
            if (/^right\\s/i.test(text)) {
                text = text.replace(/^right\\s/i, 'write ');
            }
            // Handle "cursor right" ‚Üí "cursor write" 
            text = text.replace(/\\b(cursor|claude|chatgpt|terminal)\\s+right\\s/gi, '$1 write ');
            
            const lowerText = text.toLowerCase();
            const result = {
                originalText: text,
                targetDevice: null,
                targetApp: null,
                command: text,
                action: 'type' // default action
            };
            
            // Check for device targeting first (e.g., "Jarvis, type hello")
            const allDevices = Object.values(devices);
            for (const device of allDevices) {
                const deviceName = (device.name || '').toLowerCase();
                const wakeWord = (device.wakeWord || '').toLowerCase();
                
                // Check various patterns
                const patterns = [
                    new RegExp(`^${escapeRegex(deviceName)}[,:]?\\s+(.+)`, 'i'),
                    new RegExp(`^${escapeRegex(wakeWord)}[,:]?\\s+(.+)`, 'i'),
                    new RegExp(`^hey\\s+${escapeRegex(deviceName)}[,:]?\\s+(.+)`, 'i'),
                    new RegExp(`^ok\\s+${escapeRegex(deviceName)}[,:]?\\s+(.+)`, 'i'),
                ];
                
                for (const pattern of patterns) {
                    const match = text.match(pattern);
                    if (match) {
                        result.targetDevice = device;
                        result.command = match[1].trim();
                        break;
                    }
                }
                if (result.targetDevice) break;
            }
            
            // Check for app targeting (e.g., "Cursor, write a function" or "write in cursor hello")
            for (const [appId, app] of Object.entries(knownApps)) {
                for (const keyword of app.keywords) {
                    const patterns = [
                        // "cursor, write something" or "cursor write something" or even just "cursor type"
                        new RegExp(`^${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "cursor type" or "cursor hello" (single word after app name)
                        new RegExp(`^${escapeRegex(keyword)}[,:]?\\s+(\\S+)`, 'i'),
                        // "in cursor write something"
                        new RegExp(`^(in|to|for|into)\\s+${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "send to cursor something"
                        new RegExp(`^send\\s+(to\\s+)?${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "paste in cursor something"
                        new RegExp(`^paste\\s+(in|into|to)\\s+${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "write in cursor something" or "type into cursor something"
                        new RegExp(`^(write|type|put|enter|say)\\s+(in|into|to|for)\\s+${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "write cursor something" (without preposition)
                        new RegExp(`^(write|type|put|enter|say)\\s+${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "tell cursor to write something"
                        new RegExp(`^tell\\s+${escapeRegex(keyword)}\\s+(to\\s+)?(.+)`, 'i'),
                        // "use cursor to write something"  
                        new RegExp(`^use\\s+${escapeRegex(keyword)}\\s+(to\\s+)?(.+)`, 'i'),
                        // "ask cursor something"
                        new RegExp(`^ask\\s+${escapeRegex(keyword)}[,:]?\\s+(.+)`, 'i'),
                        // "ask cursor to do something"
                        new RegExp(`^ask\\s+${escapeRegex(keyword)}\\s+to\\s+(.+)`, 'i'),
                    ];
                    
                    for (const pattern of patterns) {
                        const match = (result.command || text).match(pattern);
                        if (match) {
                            result.targetApp = { id: appId, ...app };
                            // Get the last capture group as the command
                            result.command = match[match.length - 1].trim();
                            break;
                        }
                    }
                    if (result.targetApp) break;
                }
                if (result.targetApp) break;
            }
            
            // Check for action keywords
            const actionPatterns = {
                'type': /^(type|write|enter|input|say)\\s+(.+)/i,
                'paste': /^paste\\s+(.+)/i,
                'search': /^(search|google|look up|search for)\\s+(.+)/i,
                'run': /^(run|execute|do)\\s+(.+)/i,
                'open_tab': /^open\\s+(a\\s+)?new\\s+tab$/i,
                'open_url': /^(open|go to|navigate to|launch)\\s+(.+)/i,
            };
            
            // If we have a target app but no action keyword match, default to typing the rest
            // e.g., "cursor hello world" ‚Üí type "hello world" in cursor
            if (result.targetApp && result.command && !Object.values(actionPatterns).some(p => p.test(result.command))) {
                // No action keyword found - just type the content
                result.action = 'type';
                // result.command is already set to the text after the app name
            }
            
            // Common website shortcuts
            const websiteShortcuts = {
                'google': 'https://google.com',
                'youtube': 'https://youtube.com',
                'github': 'https://github.com',
                'twitter': 'https://twitter.com',
                'x': 'https://twitter.com',
                'facebook': 'https://facebook.com',
                'reddit': 'https://reddit.com',
                'amazon': 'https://amazon.com',
                'netflix': 'https://netflix.com',
                'spotify': 'https://spotify.com',
                'linkedin': 'https://linkedin.com',
                'instagram': 'https://instagram.com',
                'gmail': 'https://gmail.com',
                'google docs': 'https://docs.google.com',
                'google sheets': 'https://sheets.google.com',
                'google drive': 'https://drive.google.com',
                'chatgpt': 'https://chat.openai.com',
                'claude': 'https://claude.ai',
                'stackoverflow': 'https://stackoverflow.com',
                'stack overflow': 'https://stackoverflow.com',
            };
            
            for (const [action, pattern] of Object.entries(actionPatterns)) {
                const match = result.command.match(pattern);
                if (match) {
                    result.action = action;
                    
                    // Handle URL opening specially
                    if (action === 'open_url') {
                        var site = match[2].trim().toLowerCase();
                        // Check if it's a known shortcut
                        if (websiteShortcuts[site]) {
                            result.command = websiteShortcuts[site];
                        } else if (site.includes('.')) {
                            // Looks like a domain
                            result.command = site.startsWith('http') ? site : 'https://' + site;
                        } else {
                            // Treat as a search
                            result.action = 'search';
                            result.command = site;
                        }
                    } else if (action === 'open_tab') {
                        result.command = '';
                    } else {
                        result.command = match[match.length - 1].trim();
                    }
                    break;
                }
            }
            
            return result;
        }
        
        function escapeRegex(string) {
            // Escape special regex characters
            return String(string).replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
        }
        
        // Route a command to a specific device
        function routeCommandToDevice(targetDevice, command, action, targetApp = null) {
            socket.emit('route_command', {
                fromDeviceId: deviceId,
                toDeviceId: targetDevice.id,
                command: command,
                action: action || 'type',
                targetApp: targetApp,
                timestamp: new Date().toISOString()
            });
            
            showLastCommand(targetDevice.icon || 'üíª', `‚Üí ${targetDevice.name}`, command);
            addActivity(`üì§ Sent to ${targetDevice.name}: "${command.substring(0, 40)}..."`, 'success');
        }
        
        // Test desktop client connection
        async function testDesktopConnection() {
            console.log('Testing desktop connection...');
            
            // ELECTRON: Check if Electron app control is available
            if (isElectron && window.electronAPI?.canControlApps) {
                try {
                    const canControl = await window.electronAPI.canControlApps();
                    if (canControl) {
                        addActivity('‚úÖ Electron app control available! No separate client needed.', 'success');
                        return;
                    }
                } catch (e) {
                    console.log('Electron control check failed:', e);
                }
            }
            
            // Fallback: Check for desktop client
            console.log('All devices:', devices);
            const desktopClient = Object.values(devices).find(d => d.type === 'desktop_client');
            
            if (desktopClient) {
                addActivity(`‚úÖ Desktop client found: ${desktopClient.name} (${desktopClient.id})`, 'success');
                console.log('Desktop client:', desktopClient);
                
                // Send a test ping
                socket.emit('route_command', {
                    fromDeviceId: deviceId,
                    toDeviceId: desktopClient.id,
                    command: '--- TEST CONNECTION FROM VOICE HUB ---',
                    action: 'type',
                    timestamp: new Date().toISOString()
                });
                addActivity(`üì§ Sent test ping to ${desktopClient.name}`, 'info');
            } else {
                addActivity('‚ÑπÔ∏è Use the Electron app for app control (no separate client needed)', 'info');
                console.log('No desktop client. Device types:', Object.values(devices).map(d => ({name: d.name, type: d.type})));
            }
        }
        
        // Execute a manually typed command
        async function executeManualCommand() {
            const input = document.getElementById('manual-command-input');
            const command = input.value.trim();
            
            if (!command) {
                addActivity('‚ö†Ô∏è Please enter a command first', 'warning');
                return;
            }
            
            addActivity(`‚å®Ô∏è Executing: "${command}"`, 'info');
            console.log('[MANUAL] Executing command:', command);
            
            // Process it just like a voice command
            try {
                const result = await handleTranscript(command);
                
                if (result && result.success !== false) {
                    addActivity('‚úÖ Command executed!', 'success');
                    input.value = ''; // Clear input on success
                } else if (result && result.error) {
                    addActivity('‚ùå ' + result.error, 'warning');
                }
            } catch (e) {
                console.error('[MANUAL] Error:', e);
                addActivity('‚ùå Error: ' + e.message, 'warning');
            }
        }
        
        // Test typing to Cursor app
        async function testTypeToCursor() {
            console.log('Testing type to Cursor...');
            
            // ELECTRON: Use built-in app control
            if (isElectron && window.electronAPI?.executeCommand) {
                try {
                    addActivity('üñ•Ô∏è Using Electron to type to Cursor...', 'info');
                    const result = await window.electronAPI.executeCommand(
                        'type',
                        'Hello from Cortona! This is a test.',
                        'cursor'
                    );
                    if (result.success) {
                        addActivity('‚úÖ Typed to Cursor successfully!', 'success');
                    } else {
                        addActivity('‚ùå Failed: ' + (result.error || 'Unknown error'), 'warning');
                    }
                } catch (e) {
                    addActivity('‚ùå Electron error: ' + e.message, 'warning');
                }
                return;
            }
            
            // Fallback: Use desktop client
            const desktopClient = Object.values(devices).find(d => d.type === 'desktop_client');
            
            if (desktopClient) {
                socket.emit('route_command', {
                    fromDeviceId: deviceId,
                    toDeviceId: desktopClient.id,
                    command: 'Hello from Voice Hub! This is a test.',
                    action: 'type',
                    targetApp: 'cursor',
                    timestamp: new Date().toISOString()
                });
                addActivity('üì§ Sent test text to Cursor', 'success');
            } else {
                addActivity('‚ùå No desktop client! Use the Electron app for app control.', 'warning');
            }
        }
        
        // Handle an incoming routed command
        function handleRoutedCommand(data) {
            const { command, action, fromDeviceId } = data;
            const fromDevice = devices[fromDeviceId];
            const fromName = fromDevice?.name || 'Unknown Device';
            
            addActivity(`üì• Received from ${fromName}: "${command.substring(0, 40)}..."`, 'info');
            playSound('activate');
            
            // Execute the command
            if (action === 'type' || action === 'paste') {
                handleTranscript(command);
            }
            
            showLastCommand('üì•', `‚Üê From ${fromName}`, command);
        }
        
        // Show the last command in the UI
        function showLastCommand(icon, target, text) {
            const box = document.getElementById('last-command-box');
            document.getElementById('last-command-icon').textContent = icon;
            document.getElementById('last-command-target').textContent = target;
            document.getElementById('last-command-text').textContent = text.length > 60 ? text.substring(0, 60) + '...' : text;
            box.style.display = 'block';
            
            // Highlight effect
            box.style.borderColor = 'var(--accent)';
            box.style.border = '1px solid var(--accent)';
            setTimeout(() => {
                box.style.border = 'none';
            }, 2000);
        }
        
        // Render available devices for routing
        function renderAvailableDevices() {
            const container = document.getElementById('available-devices');
            if (!container) return; // Element may not exist
            
            const deviceList = Object.values(devices);
            
            if (deviceList.length === 0) {
                container.innerHTML = '<div style="color: var(--text-muted); font-size: 13px;">No devices available</div>';
                return;
            }
            
            container.innerHTML = deviceList.map(d => `
                <div class="route-item" style="display: flex; align-items: center; gap: 10px; padding: 10px 14px; background: var(--bg-secondary); border-radius: 10px; font-size: 14px; ${d.id === deviceId ? 'border: 1px solid var(--accent);' : ''}">
                    <span style="font-size: 20px;">${d.icon || 'üíª'}</span>
                    <div style="flex: 1;">
                        <div style="font-weight: 500;">${d.name || 'Unnamed'}</div>
                        <div style="font-size: 12px; color: var(--text-muted);">"${d.wakeWord || 'hey computer'}"</div>
                    </div>
                    ${d.id === deviceId ? '<span style="font-size: 10px; background: var(--accent); color: var(--bg-primary); padding: 2px 8px; border-radius: 50px;">THIS DEVICE</span>' : ''}
                </div>
            `).join('');
        }
        
        // ============================================================
        // FUZZY WAKE WORD MATCHING
        // ============================================================
        
        // Calculate similarity between two strings (0-1)
        function similarity(s1, s2) {
            s1 = s1.toLowerCase().trim();
            s2 = s2.toLowerCase().trim();
            
            if (s1 === s2) return 1;
            if (s1.length === 0 || s2.length === 0) return 0;
            
            // Check if one contains the other
            if (s1.includes(s2) || s2.includes(s1)) return 0.9;
            
            // Levenshtein distance
            const matrix = [];
            for (let i = 0; i <= s1.length; i++) {
                matrix[i] = [i];
            }
            for (let j = 0; j <= s2.length; j++) {
                matrix[0][j] = j;
            }
            for (let i = 1; i <= s1.length; i++) {
                for (let j = 1; j <= s2.length; j++) {
                    const cost = s1[i-1] === s2[j-1] ? 0 : 1;
                    matrix[i][j] = Math.min(
                        matrix[i-1][j] + 1,
                        matrix[i][j-1] + 1,
                        matrix[i-1][j-1] + cost
                    );
                }
            }
            const distance = matrix[s1.length][s2.length];
            const maxLen = Math.max(s1.length, s2.length);
            return 1 - (distance / maxLen);
        }
        
        // Check if the transcript is a "send to [device]" command
        // This handles both device NAME and wake word when prefixed with "send to"
        function checkForCrossDeviceCommand(transcript) {
            const lowerTranscript = transcript.toLowerCase().trim();
            
            // Patterns that indicate cross-device routing
            const sendPatterns = [
                /^send\\s+to\\s+(.+?)\\s+(?:type\\s+|write\\s+|say\\s+)?(.+)$/i,
                /^tell\\s+(.+?)\\s+to\\s+(?:type\\s+|write\\s+)?(.+)$/i,
                /^on\\s+(.+?)\\s+(?:type\\s+|write\\s+)(.+)$/i,
                /^(.+?)\\s+type\\s+(.+)$/i,  // "Windows PC type hello"
                /^(.+?)\\s+write\\s+(.+)$/i  // "MacBook write hello"
            ];
            
            // Get all other devices
            var otherDevices = Object.values(devices).filter(function(d) {
                return d.id !== deviceId && d.online !== false;
            });
            
            // First check for explicit "send to" patterns (highest priority)
            for (var p = 0; p < 3; p++) {
                var match = lowerTranscript.match(sendPatterns[p]);
                if (match) {
                    var targetName = match[1].trim();
                    var command = match[2].trim();
                    
                    // Find matching device by name OR wake word
                    for (var i = 0; i < otherDevices.length; i++) {
                        var device = otherDevices[i];
                        var deviceName = (device.name || '').toLowerCase();
                        var deviceWake = (device.wakeWord || '').toLowerCase();
                        
                        if (targetName === deviceName || targetName === deviceWake || 
                            deviceName.includes(targetName) || targetName.includes(deviceName)) {
                            return {
                                device: device,
                                command: command,
                                explicit: true  // Explicit send command
                            };
                        }
                    }
                }
            }
            
            // Then check for "[device name] type/write" patterns
            for (var i = 0; i < otherDevices.length; i++) {
                var device = otherDevices[i];
                var deviceName = (device.name || '').toLowerCase();
                
                // Only match by device NAME (not wake word) for implicit routing
                // This prevents accidentally triggering other devices
                if (deviceName && lowerTranscript.startsWith(deviceName)) {
                    var afterName = transcript.substring(deviceName.length).trim();
                    // Must have "type" or "write" after the device name
                    var typeMatch = afterName.match(/^(?:type|write)\\s+(.+)$/i);
                    if (typeMatch) {
                        return {
                            device: device,
                            command: typeMatch[1],
                            explicit: false
                        };
                    }
                }
            }
            
            return null;
        }
        
        // Route a command to another device
        function routeToOtherDevice(targetDevice, command) {
            console.log('Routing to', targetDevice.name, ':', command);
            
            // Send command via socket to the target device
            socket.emit('route_command', {
                fromDeviceId: deviceId,
                toDeviceId: targetDevice.id,
                command: command,
                action: 'type',
                crossDevice: true,
                timestamp: new Date().toISOString()
            });
            
            showLastCommand(targetDevice.icon || 'üíª', '‚Üí ' + targetDevice.name, command);
            addActivity('üì§ Sent to ' + targetDevice.name + ': "' + command.substring(0, 40) + '..."', 'success');
            document.getElementById('transcript').textContent = 'üì° ‚Üí ' + targetDevice.name + ': "' + command + '"';
        }
        
        // Check if the user said "stop" as a command (not as part of a sentence)
        function checkForStopCommand(text) {
            const lower = text.toLowerCase().trim();
            
            // Exact "stop" command
            if (lower === 'stop' || lower === 'stop listening' || lower === 'stop recording') {
                return true;
            }
            
            // Ends with "stop" as a command (like "ok stop" or "please stop")
            if (lower.endsWith(' stop') && lower.split(' ').length <= 3) {
                return true;
            }
            
            // Common stop phrases
            const stopPhrases = ['stop now', 'thats enough', 'enough', 'end recording', 'stop dictation', 'cancel', "that's enough", "i'm done", "end dictation", "that's all"];
            if (stopPhrases.includes(lower)) {
                return true;
            }
            
            // Note: Claude will also intelligently detect stop commands for edge cases
            // This is just the fast path for obvious stops
            
            return false;
        }
        
        // Handle stop command - shared logic for both quick stop and Claude-detected stop
        function handleStopCommand() {
            const transcriptEl = document.getElementById('transcript');
            const wakeWord = currentDevice?.wakeWord?.toLowerCase() || 'hey computer';
            
            addActivity('üõë Stop command - ending dictation', 'info');
            
            // End active dictation
            isActiveDictation = false;
            
            if (alwaysListen) {
                // Stay in always-listen mode, just go back to waiting for wake word
                transcriptEl.textContent = `Ready for "${wakeWord}"`;
                transcriptEl.classList.remove('active');
                document.getElementById('voice-status').textContent = 'Standby';
                document.getElementById('voice-hint').innerHTML = `Say "<strong>${wakeWord}</strong>" to activate`;
                addChatMessage('Okay, standing by. Say your wake word when you need me.', 'jarvis');
                // Recognition keeps running to listen for wake word
            } else {
                // Not in always-listen mode, fully stop
                stopListening();
                transcriptEl.textContent = 'Stopped.';
                addChatMessage('Stopped listening. Click the mic when you need me.', 'jarvis');
            }
            updateUI();
        }
        
        // Check if transcript contains wake word with fuzzy matching
        function detectWakeWord(transcript, wakeWord) {
            const lowerTranscript = transcript.toLowerCase();
            const lowerWake = wakeWord.toLowerCase();
            
            // Exact match - always works
            if (lowerTranscript.includes(lowerWake)) {
                return { detected: true, index: lowerTranscript.indexOf(lowerWake), length: lowerWake.length };
            }
            
            // Fuzzy matching based on sensitivity
            // Sensitivity 5 = exact only (threshold 1.0)
            // Sensitivity 1 = very fuzzy (threshold 0.5)
            const thresholds = { 1: 0.5, 2: 0.6, 3: 0.7, 4: 0.85, 5: 1.0 };
            const threshold = thresholds[sensitivity] || 0.7;
            
            // Split transcript into chunks and check each
            const words = lowerTranscript.split(' ');
            const wakeWords = lowerWake.split(' ');
            
            for (let i = 0; i <= words.length - wakeWords.length; i++) {
                const chunk = words.slice(i, i + wakeWords.length).join(' ');
                const sim = similarity(chunk, lowerWake);
                
                if (sim >= threshold) {
                    const index = lowerTranscript.indexOf(chunk);
                    return { detected: true, index, length: chunk.length, similarity: sim };
                }
            }
            
            // Also check individual words for single-word wake words
            if (wakeWords.length === 1) {
                for (const word of words) {
                    const sim = similarity(word, lowerWake);
                    if (sim >= threshold) {
                        const index = lowerTranscript.indexOf(word);
                        return { detected: true, index, length: word.length, similarity: sim };
                    }
                }
            }
            
            return { detected: false };
        }
        
        // ============================================================
        // SPEECH RECOGNITION
        // ============================================================
        
        function initSpeechRecognition() {
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = currentDevice?.language || 'en-US';
            
            // Simple restart - Chrome fires onend frequently, just restart silently
            recognition.onend = () => {
                console.log('[MIC] onend - alwaysListen:', alwaysListen, 'continuousMode:', continuousMode);
                
                const shouldRestart = (alwaysListen || continuousMode) && currentDevice;
                isListening = false;
                
                if (shouldRestart) {
                    // Keep isRestarting true to prevent UI flicker
                    isRestarting = true;
                    
                    // Immediate restart with minimal delay
                    setTimeout(() => {
                        if ((alwaysListen || continuousMode) && !isListening) {
                            try {
                                recognition.start();
                                console.log('[MIC] Restarted successfully');
                            } catch (e) {
                                console.log('[MIC] Restart error:', e.message);
                                // If it fails, try reinitializing
                                if (e.name === 'InvalidStateError') {
                                initSpeechRecognition();
                                setTimeout(() => {
                                    if (alwaysListen || continuousMode) {
                                            try { recognition.start(); } catch (e2) { console.log('[MIC] Re-init start failed:', e2.message); }
                                    }
                                    }, 200);
                            }
                        }
                        }
                    }, 100); // Very short delay - just enough to avoid race condition
                } else {
                    isRestarting = false;
                    updateUI();
                }
            };
            
            recognition.onstart = () => {
                console.log('[MIC] onstart - mic is now listening');
                isListening = true;
                isRestarting = false;
                hasInitialized = true;
                updateUI();
                if (!alwaysListen && !hasInitialized) {
                    addActivity('Started listening', 'info');
                }
                socket.emit('device_status', { deviceId, status: 'listening' });
            };
            
            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                const transcriptEl = document.getElementById('transcript');
                const wakeWord = currentDevice?.wakeWord?.toLowerCase() || 'hey computer';
                
                // PRIVACY: In always-listen mode, NEVER show what user is saying
                // Only show the ready message or wake word detection
                if (alwaysListen && !isActiveDictation && !continuousMode) {
                    if (interimTranscript) {
                        const interimDetection = detectWakeWord(interimTranscript, wakeWord);
                        if (interimDetection.detected) {
                            // Only show that wake word was detected, nothing else
                            transcriptEl.textContent = 'üéØ Wake word detected...';
                            transcriptEl.classList.add('active');
                        }
                        // NEVER show what user said if wake word not detected - just keep showing ready message
                    }
                    // Don't show any transcript - keep the ready message
                } else if (interimTranscript && (isActiveDictation || continuousMode || !alwaysListen)) {
                    // Only show live transcript when:
                    // 1. In active dictation (wake word was spoken)
                    // 2. In continuous mode
                    // 3. NOT in always-listen mode (manual mic click)
                    const previewText = spellCheck(interimTranscript);
                    transcriptEl.textContent = previewText;
                    transcriptEl.classList.add('active');
                }
                
                if (finalTranscript) {
                    console.log('üé§ HEARD:', finalTranscript);
                    
                    // Quick check for obvious STOP commands (fast path, no API call needed)
                    const lowerTranscript = finalTranscript.toLowerCase().trim();
                    const isQuickStop = checkForStopCommand(lowerTranscript);
                    
                    if (isQuickStop) {
                        // Stop the current dictation session, but keep always-listen mode if enabled
                        addActivity('üõë Stop command - ending dictation', 'info');
                        addToTranscriptHistory(lowerTranscript, 'stop');
                        
                        // End active dictation
                        isActiveDictation = false;
                        
                        if (alwaysListen) {
                            // Stay in always-listen mode, just go back to waiting for wake word
                            transcriptEl.textContent = `Ready for "${wakeWord}"`;
                            transcriptEl.classList.remove('active');
                            document.getElementById('voice-status').textContent = 'Standby';
                            // Recognition keeps running to listen for wake word
                        } else {
                            // Not in always-listen mode, fully stop
                            stopListening();
                            transcriptEl.textContent = 'Stopped.';
                        }
                        updateUI();
                        return;
                    }
                    
                    // First check if command is for ANOTHER device (cross-device routing)
                    const otherDeviceMatch = checkForCrossDeviceCommand(finalTranscript);
                    
                    if (otherDeviceMatch) {
                        // Command is for another device - route it there!
                        playSound('activate');
                        addActivity('üì° Routing to ' + otherDeviceMatch.device.name + '...', 'info');
                        addToTranscriptHistory('‚Üí ' + otherDeviceMatch.device.name + ': ' + otherDeviceMatch.command, 'routed');
                        
                        // Route the command to the other device
                        routeToOtherDevice(otherDeviceMatch.device, otherDeviceMatch.command);
                        
                        // Reset transcript display
                        if (alwaysListen) {
                            setTimeout(function() {
                                transcriptEl.textContent = 'Ready for "' + wakeWord + '"';
                                transcriptEl.classList.remove('active');
                            }, 2000);
                        }
                        return;
                    }
                    
                    // Check for THIS device's wake word with fuzzy matching
                    const detection = detectWakeWord(finalTranscript, wakeWord);
                    
                    if (detection.detected) {
                        // Wake word detected!
                        const afterWakeWord = finalTranscript.substring(detection.index + detection.length).trim();
                        
                        // Play activation sound
                        playSound('activate');
                        
                        const matchInfo = detection.similarity ? ' (' + Math.round(detection.similarity * 100) + '% match)' : '';
                        addActivity('üéØ Wake word detected' + matchInfo + '!', 'success');
                        addToTranscriptHistory(wakeWord + (afterWakeWord ? ' ' + afterWakeWord : ''), 'wake');
                        currentDevice.sessions++;
                        saveDevices();
                        renderDeviceList();
                        
                        // If there's text after the wake word, process it
                        if (afterWakeWord) {
                            // Use async/await for proper Claude integration
                            (async () => {
                                const result = await handleTranscript(afterWakeWord);
                                
                                // Check if Claude detected a stop command
                                if (result && result.isStop) {
                                    handleStopCommand();
                                    return;
                                }
                                
                            // After processing command with wake word, go back to standby
                            isActiveDictation = false;
                            if (alwaysListen && !continuousMode) {
                                setTimeout(() => {
                                    transcriptEl.textContent = `Ready for "${wakeWord}"`;
                                    transcriptEl.classList.remove('active');
                                    document.getElementById('voice-status').textContent = 'Standby';
                                }, 1500);
                            }
                            })();
                        } else {
                            // Just activated, waiting for command
                            isActiveDictation = true;
                            document.getElementById('voice-status').textContent = 'Listening...';
                            transcriptEl.textContent = 'Speak your command...';
                            transcriptEl.classList.add('active');
                            document.getElementById('voice-hint').innerHTML = 'Say "stop" when done';
                        }
                    } else if (isActiveDictation || continuousMode || !alwaysListen) {
                        // In active dictation mode, process through Claude
                        addToTranscriptHistory(finalTranscript, 'command');
                        
                        // Use async/await for proper Claude integration
                        (async () => {
                            const result = await handleTranscript(finalTranscript);
                            
                            // Check if Claude detected a stop command intelligently
                            if (result && result.isStop) {
                                handleStopCommand();
                                return;
                            }
                        
                        // End the active dictation session
                        isActiveDictation = false;
                        
                        // Reset to standby mode after processing command
                        if (alwaysListen && !continuousMode) {
                            // Go back to waiting for wake word
                            setTimeout(() => {
                                transcriptEl.textContent = `Ready for "${wakeWord}"`;
                                transcriptEl.classList.remove('active');
                                document.getElementById('voice-status').textContent = 'Standby';
                                document.getElementById('voice-hint').innerHTML = `Say "<strong>${wakeWord}</strong>" to activate`;
                            }, 1500);
                            addActivity('üí¨ Command processed - waiting for wake word', 'info');
                        } else if (!alwaysListen && !continuousMode) {
                            // Manual mode without continuous - stop after command
                            setTimeout(() => {
                                if (!isActiveDictation && !continuousMode) {
                                    stopListening();
                                    transcriptEl.textContent = 'Click mic to start again';
                                    addActivity('üé§ Dictation ended', 'info');
                                }
                            }, 2000);
                        }
                        })();
                    }
                    // In always-listen mode without wake word, don't update transcript (keep showing waiting message)
                }
            };
            
            recognition.onerror = (event) => {
                console.log('[MIC] onerror:', event.error);
                
                // Handle common non-fatal errors - these will trigger onend which handles restart
                if (event.error === 'no-speech') {
                    // Normal - just means no one spoke during the timeout
                    console.log('[MIC] No speech detected, will restart via onend');
                    return;
                }
                
                if (event.error === 'aborted') {
                    // Normal - recognition was stopped
                    console.log('[MIC] Recognition aborted');
                    return;
                }
                
                // Log actual errors with more detail
                console.error('[MIC] Speech recognition error:', event.error, event);
                
                if (event.error === 'not-allowed') {
                    addActivity('‚ùå Microphone access denied. Click mic button to grant permission.', 'warning');
                    alwaysListen = false;
                    isRestarting = false;
                    document.getElementById('toggle-always-listen').classList.remove('active');
                    updateUI();
                } else if (event.error === 'audio-capture') {
                    addActivity('‚ùå No microphone detected. Check System Preferences > Security > Microphone.', 'warning');
                    isRestarting = false;
                    updateUI();
                } else if (event.error === 'network') {
                    // In Electron, switch to local Whisper
                    if (isElectron && !useWhisper) {
                        console.log('[MIC] Network error in Electron - switching to local Whisper');
                        addActivity('üîÑ Switching to local Whisper for speech recognition...', 'info');
                        useWhisper = true;
                        startWhisperRecording();
                        return;
                    }
                    addActivity('‚ö†Ô∏è Network error. Speech recognition requires internet.', 'warning');
                } else if (event.error === 'service-not-allowed') {
                    addActivity('‚ùå Speech service blocked. Try: System Preferences > Security > Privacy > Microphone', 'warning');
                    isRestarting = false;
                    updateUI();
                } else {
                    addActivity(`Speech error: ${event.error}`, 'warning');
                }
                isListening = false;
                updateUI();
            };
        }
        
        // ============================================================
        // WHISPER SPEECH RECOGNITION (Cloud API - OpenAI)
        // ============================================================
        
        async function checkWhisperService() {
            // For cloud Whisper, just check if API is available
            if (useCloudWhisper) {
                try {
                    const response = await fetch('/api/openai-status');
                    if (response.ok) {
                        const data = await response.json();
                        return data.available && data.features?.whisper;
                    }
                    return false;
                } catch (e) {
                    console.log('[WHISPER-CLOUD] Status check failed:', e.message);
                    return false;
                }
            }
            
            // Fallback: In Electron, use IPC for local Whisper
            if (isElectron && window.electronAPI?.whisperHealth) {
                try {
                    const result = await window.electronAPI.whisperHealth();
                    console.log('[WHISPER-LOCAL] Health check via IPC:', result);
                    return result.available && result.modelLoaded;
                } catch (e) {
                    console.log('[WHISPER-LOCAL] IPC health check failed:', e);
                    return false;
                }
            }
            
            // Fallback to direct local fetch
            try {
                const response = await fetch(`${WHISPER_LOCAL_URL}/health`);
                if (response.ok) {
                    const data = await response.json();
                    return data.model_loaded;
                }
                return false;
            } catch (e) {
                console.log('[WHISPER-LOCAL] Service not available:', e.message);
                return false;
            }
        }
        
        async function startWhisperRecording() {
            console.log('[WHISPER] Starting recording mode, cloud:', useCloudWhisper);
            playChime('start');  // Audio feedback
            
            // Check if Whisper service is running
            const whisperAvailable = await checkWhisperService();
            if (!whisperAvailable) {
                if (useCloudWhisper) {
                    addActivity('‚ö†Ô∏è OpenAI API not configured. Add OPENAI_API_KEY in Render settings.', 'warning');
                } else {
                    addActivity('‚ö†Ô∏è Local Whisper service not running. Restart the app.', 'warning');
                }
                useWhisper = false;
                return;
            }
            
            addActivity(useCloudWhisper ? '‚òÅÔ∏è Using OpenAI Whisper (cloud)' : '‚úÖ Connected to local Whisper', 'success');
            
            try {
                // Get microphone access
                whisperMediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Start audio level visualization
                startAudioLevelTracking(whisperMediaStream);
                
                // Start continuous recording loop
                whisperContinuousRecord();
                
            } catch (e) {
                console.error('[WHISPER] Failed to get microphone:', e);
                addActivity('‚ùå Microphone access denied', 'warning');
                useWhisper = false;
            }
        }
        
        function whisperContinuousRecord() {
            if (!useWhisper || !whisperMediaStream) return;
            
            const chunks = [];
            whisperRecorder = new MediaRecorder(whisperMediaStream, { mimeType: 'audio/webm' });
            
            whisperRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    chunks.push(e.data);
                }
            };
            
            whisperRecorder.onstop = async () => {
                if (chunks.length === 0) {
                    // No audio, restart
                    if (useWhisper && (alwaysListen || continuousMode)) {
                        setTimeout(whisperContinuousRecord, 100);
                    }
                    return;
                }
                
                const blob = new Blob(chunks, { type: 'audio/webm' });
                
                // Only transcribe if there's meaningful audio (> 1KB)
                if (blob.size > 1000) {
                    await transcribeWithWhisper(blob);
                }
                
                // Continue recording if in always-listen mode
                if (useWhisper && (alwaysListen || continuousMode || isActiveDictation)) {
                    setTimeout(whisperContinuousRecord, 100);
                }
            };
            
            // Record for 3 seconds at a time
            whisperRecorder.start();
            isListening = true;
            updateUI();
            
            setTimeout(() => {
                if (whisperRecorder && whisperRecorder.state === 'recording') {
                    whisperRecorder.stop();
                }
            }, 3000);
        }
        
        async function transcribeWithWhisper(audioBlob) {
            try {
                // CLOUD WHISPER (preferred - fast, accurate)
                if (useCloudWhisper) {
                    console.log('[WHISPER-CLOUD] Sending audio to OpenAI, size:', audioBlob.size);
                    
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'audio.webm');
                    
                    const response = await fetch('/api/whisper', {
                        method: 'POST',
                        body: formData,
                        headers: {
                            'X-CSRFToken': csrfToken
                        }
                    });
                    
                    if (!response.ok) {
                        console.error('[WHISPER-CLOUD] Transcription failed:', response.status);
                        const errorData = await response.json().catch(() => ({}));
                        if (errorData.error) {
                            addActivity(`‚ùå ${errorData.error}`, 'warning');
                        }
                        return;
                    }
                    
                    const data = await response.json();
                    if (data.success && data.text) {
                        console.log('[WHISPER-CLOUD] Transcribed:', data.text);
                        processWhisperTranscript(data.text);
                    }
                    return;
                }
                
                // LOCAL WHISPER (fallback)
                // In Electron, use IPC to transcribe
                if (isElectron && window.electronAPI?.whisperTranscribe) {
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    
                    console.log('[WHISPER-LOCAL] Sending audio via IPC, size:', arrayBuffer.byteLength);
                    const result = await window.electronAPI.whisperTranscribe(arrayBuffer);
                    
                    if (result.success && result.text) {
                        console.log('[WHISPER-LOCAL] Transcribed via IPC:', result.text);
                        processWhisperTranscript(result.text);
                    } else if (result.error) {
                        console.error('[WHISPER-LOCAL] IPC transcription error:', result.error);
                    }
                    return;
                }
                
                // Direct local fetch
                const formData = new FormData();
                formData.append('audio', audioBlob, 'audio.webm');
                
                const response = await fetch(`${WHISPER_LOCAL_URL}/transcribe`, {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    console.error('[WHISPER-LOCAL] Transcription failed:', response.status);
                    return;
                }
                
                const data = await response.json();
                const text = data.text?.trim();
                
                if (text && text.length > 0) {
                    console.log('[WHISPER-LOCAL] Transcribed:', text);
                    processWhisperTranscript(text);
                }
                
            } catch (e) {
                console.error('[WHISPER] Transcription error:', e);
            }
        }
        
        // ============================================================
        // AUDIO FEEDBACK (Chimes) & LEVEL VISUALIZATION
        // ============================================================
        
        let audioContext = null;
        let audioFeedbackEnabled = true;
        let levelAnalyser = null;
        let levelInterval = null;
        
        function getAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            return audioContext;
        }
        
        // Audio Level Visualization
        function startAudioLevelTracking(stream) {
            try {
                const ctx = getAudioContext();
                levelAnalyser = ctx.createAnalyser();
                levelAnalyser.fftSize = 256;
                levelAnalyser.smoothingTimeConstant = 0.4;
                
                const source = ctx.createMediaStreamSource(stream);
                source.connect(levelAnalyser);
                ctx.resume().catch(() => {});
                
                const sample = new Uint8Array(levelAnalyser.frequencyBinCount);
                
                // Show visualization
                const container = document.getElementById('audio-level-container');
                const recordingDot = document.getElementById('recording-dot');
                if (container) container.classList.add('active');
                if (recordingDot) recordingDot.classList.add('active');
                
                // Update bars at ~20fps
                levelInterval = setInterval(() => {
                    if (!levelAnalyser) {
                        stopAudioLevelTracking();
                        return;
                    }
                    
                    levelAnalyser.getByteTimeDomainData(sample);
                    
                    // Calculate RMS (root mean square) for audio level
                    let sumSquares = 0;
                    for (let i = 0; i < sample.length; i++) {
                        const deviation = (sample[i] - 128) / 128;
                        sumSquares += deviation * deviation;
                    }
                    const rms = Math.sqrt(sumSquares / sample.length);
                    
                    // Normalize to 0-1 range (multiply by 4 for sensitivity)
                    const level = Math.max(0, Math.min(1, rms * 4.0));
                    
                    // Update bars with different scales for visual effect
                    const baseScales = [0.35, 0.6, 1, 0.6, 0.35];
                    for (let i = 0; i < 5; i++) {
                        const bar = document.getElementById('bar-' + i);
                        if (bar) {
                            // Height ranges from 4px to 24px based on audio level
                            const height = Math.max(4, Math.min(24, (level * 24 + 4) * baseScales[i]));
                            bar.style.height = height + 'px';
                        }
                    }
                }, 50);
                
                console.log('[AUDIO] Level tracking started');
            } catch (e) {
                console.warn('[AUDIO] Level tracking unavailable:', e.message);
            }
        }
        
        function stopAudioLevelTracking() {
            if (levelInterval) {
                clearInterval(levelInterval);
                levelInterval = null;
            }
            levelAnalyser = null;
            
            // Hide visualization
            const container = document.getElementById('audio-level-container');
            const recordingDot = document.getElementById('recording-dot');
            if (container) container.classList.remove('active');
            if (recordingDot) recordingDot.classList.remove('active');
            
            // Reset bars
            for (let i = 0; i < 5; i++) {
                const bar = document.getElementById('bar-' + i);
                if (bar) bar.style.height = '4px';
            }
            
            console.log('[AUDIO] Level tracking stopped');
        }
        
        function playChime(type = 'start') {
            if (!audioFeedbackEnabled) return;
            
            try {
                const ctx = getAudioContext();
                const oscillator = ctx.createOscillator();
                const gainNode = ctx.createGain();
                
                oscillator.connect(gainNode);
                gainNode.connect(ctx.destination);
                
                if (type === 'start') {
                    // Rising tone for start (friendly "ready" sound)
                    oscillator.frequency.setValueAtTime(440, ctx.currentTime); // A4
                    oscillator.frequency.exponentialRampToValueAtTime(880, ctx.currentTime + 0.1); // A5
                    gainNode.gain.setValueAtTime(0.3, ctx.currentTime);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.15);
                    oscillator.start(ctx.currentTime);
                    oscillator.stop(ctx.currentTime + 0.15);
                } else if (type === 'stop') {
                    // Falling tone for stop (gentle "done" sound)
                    oscillator.frequency.setValueAtTime(660, ctx.currentTime); // E5
                    oscillator.frequency.exponentialRampToValueAtTime(440, ctx.currentTime + 0.15); // A4
                    gainNode.gain.setValueAtTime(0.25, ctx.currentTime);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.2);
                    oscillator.start(ctx.currentTime);
                    oscillator.stop(ctx.currentTime + 0.2);
                } else if (type === 'error') {
                    // Double low tone for error
                    oscillator.frequency.setValueAtTime(220, ctx.currentTime); // A3
                    gainNode.gain.setValueAtTime(0.3, ctx.currentTime);
                    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.1);
                    oscillator.start(ctx.currentTime);
                    oscillator.stop(ctx.currentTime + 0.1);
                    
                    // Second beep
                    setTimeout(() => {
                        const osc2 = ctx.createOscillator();
                        const gain2 = ctx.createGain();
                        osc2.connect(gain2);
                        gain2.connect(ctx.destination);
                        osc2.frequency.setValueAtTime(220, ctx.currentTime);
                        gain2.gain.setValueAtTime(0.3, ctx.currentTime);
                        gain2.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.1);
                        osc2.start(ctx.currentTime);
                        osc2.stop(ctx.currentTime + 0.1);
                    }, 150);
                }
                
                console.log('[AUDIO] Played chime:', type);
            } catch (e) {
                console.log('[AUDIO] Chime failed:', e.message);
            }
        }
        
        // ============================================================
        // FILLER WORD REMOVAL & CUSTOM WORD REPLACEMENTS
        // ============================================================
        
        // Filler sounds to always remove
        const fillerSounds = ['um', 'uh', 'uhh', 'umm', 'er', 'err', 'ah', 'ahh', 'hmm'];
        
        // Patterns to remove (bracketed content, etc.)
        const fillerPatterns = [
            /\[inaudible\]/gi,
            /\[unclear\]/gi,
            /\[music\]/gi,
            /\[applause\]/gi,
            /\([^)]*\)/g,  // Parenthetical content
            /\.{3,}/g,     // Multiple periods
        ];
        
        // User-configurable word replacements (misrecognition ‚Üí correct)
        // Users can add their own via settings
        let wordReplacements = {
            // Common misrecognitions
            'coarser': 'cursor',
            'curser': 'cursor',
            'coursor': 'cursor',
            'cloud': 'claude',
            'claud': 'claude',
            'vs code': 'vscode',
            'chat gpt': 'chatgpt',
            'co-pilot': 'copilot',
            // Add your own below
        };
        
        // Snippets (trigger ‚Üí expansion)
        let snippets = {
            // Examples - users can add their own
            // 'my email': 'user@example.com',
            // 'my phone': '555-123-4567',
            // 'sig': 'Best regards, Your Name',
        };
        
        // Load saved replacements/snippets from localStorage
        function loadUserDictionary() {
            try {
                const savedReplacements = localStorage.getItem('cortona_word_replacements');
                if (savedReplacements) {
                    wordReplacements = { ...wordReplacements, ...JSON.parse(savedReplacements) };
                }
                const savedSnippets = localStorage.getItem('cortona_snippets');
                if (savedSnippets) {
                    snippets = { ...snippets, ...JSON.parse(savedSnippets) };
                }
                console.log('[DICTIONARY] Loaded', Object.keys(wordReplacements).length, 'replacements,', Object.keys(snippets).length, 'snippets');
            } catch (e) {
                console.warn('[DICTIONARY] Failed to load:', e);
            }
        }
        
        // Save to localStorage
        function saveUserDictionary() {
            try {
                localStorage.setItem('cortona_word_replacements', JSON.stringify(wordReplacements));
                localStorage.setItem('cortona_snippets', JSON.stringify(snippets));
            } catch (e) {
                console.warn('[DICTIONARY] Failed to save:', e);
            }
        }
        
        // Apply word replacements
        function applyWordReplacements(text) {
            if (!text) return text;
            
            let result = text;
            
            // Sort by key length (longest first) for proper replacement order
            const entries = Object.entries(wordReplacements)
                .sort((a, b) => b[0].length - a[0].length);
            
            for (const [key, replacement] of entries) {
                if (!key) continue;
                const regex = new RegExp(`\\b${escapeRegex(key)}\\b`, 'gi');
                result = result.replace(regex, replacement);
            }
            
            return result;
        }
        
        // Apply snippet expansions
        function applySnippetExpansions(text) {
            if (!text || Object.keys(snippets).length === 0) return { text, expansions: [] };
            
            let result = text;
            const expansions = [];
            
            // Sort by trigger length (longest first)
            const entries = Object.entries(snippets)
                .sort((a, b) => b[0].length - a[0].length);
            
            for (const [trigger, content] of entries) {
                if (!trigger) continue;
                const regex = new RegExp(`\\b${escapeRegex(trigger)}\\b`, 'gi');
                if (regex.test(result)) {
                    result = result.replace(regex, content);
                    expansions.push({ trigger, content });
                    console.log('[SNIPPET] Expanded:', trigger, '‚Üí', content);
                }
            }
            
            return { text: result, expansions };
        }
        
        // Remove filler words
        function removeFillerWords(text) {
            if (!text) return text;
            
            let cleaned = text;
            
            // Remove bracketed/parenthetical content
            fillerPatterns.forEach(pattern => {
                cleaned = cleaned.replace(pattern, '');
            });
            
            // Remove filler sounds (only obvious ones)
            fillerSounds.forEach(filler => {
                const regex = new RegExp(`\\b${escapeRegex(filler)}\\b[,]?\\s*`, 'gi');
                cleaned = cleaned.replace(regex, '');
            });
            
            // Apply word replacements (misrecognition fixes)
            cleaned = applyWordReplacements(cleaned);
            
            // Apply snippet expansions
            const { text: expanded } = applySnippetExpansions(cleaned);
            cleaned = expanded;
            
            // Clean up extra spaces and punctuation
            cleaned = cleaned.replace(/\s+/g, ' ').trim();
            cleaned = cleaned.replace(/^[,\s]+/, '').replace(/[,\s]+$/, '');
            cleaned = cleaned.replace(/\s+([,.])/g, '$1');
            
            if (cleaned !== text) {
                console.log('[FILLER] Cleaned:', text, '‚Üí', cleaned);
            }
            
            return cleaned;
        }
        
        // Add a word replacement
        function addWordReplacement(from, to) {
            wordReplacements[from.toLowerCase()] = to;
            saveUserDictionary();
            addActivity(`üìù Added replacement: "${from}" ‚Üí "${to}"`, 'success');
        }
        
        // Add a snippet
        function addSnippet(trigger, content) {
            snippets[trigger.toLowerCase()] = content;
            saveUserDictionary();
            addActivity(`üìù Added snippet: "${trigger}"`, 'success');
        }
        
        // Load dictionary on startup
        loadUserDictionary();
        
        // ============================================================
        // TEXT-TO-SPEECH (OpenAI TTS)
        // ============================================================
        
        async function speak(text) {
            if (!ttsEnabled || !text) return;
            
            // Stop any currently playing audio
            if (currentTTSAudio) {
                currentTTSAudio.pause();
                currentTTSAudio = null;
            }
            
            try {
                console.log('[TTS] Speaking:', text.substring(0, 50) + '...');
                addActivity(`üîä Speaking...`, 'info');
                
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-CSRFToken': csrfToken
                    },
                    body: JSON.stringify({
                        text: text,
                        voice: ttsVoice
                    })
                });
                
                if (!response.ok) {
                    console.error('[TTS] Failed:', response.status);
                    return;
                }
                
                // Play the audio
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                currentTTSAudio = new Audio(audioUrl);
                
                currentTTSAudio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    currentTTSAudio = null;
                    console.log('[TTS] Finished speaking');
                };
                
                currentTTSAudio.onerror = (e) => {
                    console.error('[TTS] Playback error:', e);
                    URL.revokeObjectURL(audioUrl);
                    currentTTSAudio = null;
                };
                
                await currentTTSAudio.play();
                
            } catch (e) {
                console.error('[TTS] Error:', e);
            }
        }
        
        function stopSpeaking() {
            if (currentTTSAudio) {
                currentTTSAudio.pause();
                currentTTSAudio = null;
            }
        }
        
        function processWhisperTranscript(text) {
            // Remove filler words first
            text = removeFillerWords(text);
            if (!text || text.length < 2) return;  // Skip if empty after cleaning
            
            // This mirrors the logic from recognition.onresult
            const transcriptEl = document.getElementById('transcript');
            const wakeWord = currentDevice?.wakeWord?.toLowerCase() || 'hey computer';
            const lowerText = text.toLowerCase().trim();
            
            console.log('üé§ WHISPER HEARD:', text);
            
            // Check for stop command
            if (checkForStopCommand(lowerText)) {
                addActivity('üõë Stop command - ending dictation', 'info');
                isActiveDictation = false;
                
                if (alwaysListen) {
                    transcriptEl.textContent = `Ready for "${wakeWord}"`;
                    transcriptEl.classList.remove('active');
                    document.getElementById('voice-status').textContent = 'Standby';
                } else {
                    stopWhisperRecording();
                    transcriptEl.textContent = 'Stopped.';
                }
                updateUI();
                return;
            }
            
            // Check for wake word
            const detection = detectWakeWord(text, wakeWord);
            
            if (detection.detected || isActiveDictation || continuousMode || !alwaysListen) {
                let commandText = text;
                
                if (detection.detected) {
                    commandText = text.substring(detection.index + detection.length).trim();
                    playSound('activate');
                    addActivity('üéØ Wake word detected!', 'success');
                    
                    if (!commandText) {
                        isActiveDictation = true;
                        document.getElementById('voice-status').textContent = 'Listening...';
                        transcriptEl.textContent = 'Speak your command...';
                        transcriptEl.classList.add('active');
                        return;
                    }
                }
                
                if (commandText) {
                    transcriptEl.textContent = commandText;
                    transcriptEl.classList.add('active');
                    
                    // Process command
                    (async () => {
                        const result = await handleTranscript(commandText);
                        
                        if (result && result.isStop) {
                            handleStopCommand();
                            return;
                        }
                        
                        isActiveDictation = false;
                        if (alwaysListen && !continuousMode) {
                            setTimeout(() => {
                                transcriptEl.textContent = `Ready for "${wakeWord}"`;
                                transcriptEl.classList.remove('active');
                                document.getElementById('voice-status').textContent = 'Standby';
                            }, 1500);
                        }
                    })();
                }
            }
        }
        
        function stopWhisperRecording() {
            playChime('stop');  // Audio feedback
            stopAudioLevelTracking();  // Stop visualization
            useWhisper = false;
            
            if (whisperRecorder && whisperRecorder.state === 'recording') {
                whisperRecorder.stop();
            }
            whisperRecorder = null;
            
            if (whisperMediaStream) {
                whisperMediaStream.getTracks().forEach(track => track.stop());
                whisperMediaStream = null;
            }
            
            isListening = false;
            updateUI();
        }
        
        // Audio context - initialized on first user interaction
        let audioCtx = null;
        
        function initAudioContext() {
            if (!audioCtx) {
                try {
                    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                } catch (e) {
                    console.log('AudioContext not available');
                }
            }
            // Resume if suspended (browsers suspend until user gesture)
            if (audioCtx && audioCtx.state === 'suspended') {
                audioCtx.resume();
            }
            return audioCtx;
        }
        
        // Initialize audio on first user click
        document.addEventListener('click', () => initAudioContext(), { once: true });
        
        // Text-to-Speech for Jarvis responses
        // Show native notification (Electron) or browser notification
        function showNativeNotification(title, body) {
            if (isElectron && window.electronAPI) {
                window.electronAPI.showNotification(title, body);
            } else if ('Notification' in window && Notification.permission === 'granted') {
                new Notification(title, { body, icon: '/static/icon.png' });
            }
        }
        
        function speakText(text) {
            if (!text) return;
            
            // Also show as native notification in Electron (for when minimized)
            if (isElectron) {
                showNativeNotification('Jarvis', text);
            }
            
            // Use OpenAI TTS if available (better quality)
            if (ttsEnabled) {
                speak(text);  // Uses OpenAI TTS API
                return;
            }
            
            // Fallback to Web Speech API
            if ('speechSynthesis' in window) {
                // Cancel any ongoing speech
                window.speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.1; // Slightly faster
                utterance.pitch = 1.0;
                utterance.volume = 0.9;
                
                // Try to find a good voice
                const voices = window.speechSynthesis.getVoices();
                const preferredVoices = voices.filter(v => 
                    v.name.includes('Samantha') || 
                    v.name.includes('Google') || 
                    v.name.includes('Microsoft') ||
                    v.lang.startsWith('en')
                );
                if (preferredVoices.length > 0) {
                    utterance.voice = preferredVoices[0];
                }
                
                window.speechSynthesis.speak(utterance);
                console.log('üîä Speaking:', text);
            } else {
                console.log('Speech synthesis not available');
            }
        }
        
        // Load voices when available
        if ('speechSynthesis' in window) {
            window.speechSynthesis.onvoiceschanged = () => {
                window.speechSynthesis.getVoices(); // Cache voices
            };
        }
        
        // Add a message to the chat
        function addChatMessage(text, sender = 'user') {
            const chatMessages = document.getElementById('chat-messages');
            const transcript = document.getElementById('transcript');
            
            // Clear the initial "waiting" message
            if (transcript.textContent.includes('Say your wake word')) {
                transcript.style.display = 'none';
            }
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `chat-message ${sender}`;
            messageDiv.innerHTML = `
                <div class="sender">${sender === 'jarvis' ? 'ü§ñ Jarvis' : 'üé§ You'}</div>
                <div>${text}</div>
            `;
            
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
            
            // Keep only last 10 messages
            while (chatMessages.children.length > 11) {
                chatMessages.removeChild(chatMessages.children[1]);
            }
        }
        
        // Clear chat messages
        function clearChat() {
            const chatMessages = document.getElementById('chat-messages');
            const transcript = document.getElementById('transcript');
            chatMessages.innerHTML = '';
            transcript.style.display = 'block';
            transcript.textContent = 'Say your wake word or click the mic...';
            chatMessages.appendChild(transcript);
        }
        
        function playSound(type) {
            const ctx = initAudioContext();
            if (!ctx) return;
            
            try {
                const oscillator = ctx.createOscillator();
                const gainNode = ctx.createGain();
                
                oscillator.connect(gainNode);
                gainNode.connect(ctx.destination);
                
                if (type === 'activate') {
                    oscillator.frequency.setValueAtTime(880, ctx.currentTime);
                    oscillator.frequency.setValueAtTime(1100, ctx.currentTime + 0.1);
                } else {
                    oscillator.frequency.setValueAtTime(440, ctx.currentTime);
                }
                
                gainNode.gain.setValueAtTime(0.3, ctx.currentTime);
                gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.2);
                
                oscillator.start(ctx.currentTime);
                oscillator.stop(ctx.currentTime + 0.2);
            } catch (e) {
                // Silently fail - sounds are optional
            }
        }
        
        // Check if AI is available (GPT-4o preferred, Claude fallback)
        let claudeAvailable = false;  // Keep variable name for compatibility
        let aiProvider = null;
        let aiModel = null;
        
        // Check AI status after page loads
        setTimeout(() => {
            fetch('/api/claude-status')
                .then(r => r.json())
                .then(data => {
                    claudeAvailable = data.available;
                    aiProvider = data.provider;
                    aiModel = data.model;
                    if (claudeAvailable) {
                        const providerName = aiProvider === 'openai' ? 'GPT-4o' : 'Claude';
                        console.log(`üß† ${providerName} AI ready`);
                        addActivity(`üß† ${providerName} enabled (fast mode)`, 'success');
                    }
                })
                .catch(() => { claudeAvailable = false; });
        }, 1000);
        
        async function parseWithClaude(text) {
            try {
                // Extract assistant name from wake word (e.g., "Hey Jarvis" ‚Üí "Jarvis")
                const wakeWord = currentDevice?.wakeWord || 'hey jarvis';
                const assistantName = wakeWord.replace(/^(hey|ok|hi|hello)\s+/i, '').trim() || 'Jarvis';
                
                // Build context for adaptive AI
                const contextData = {
                    text: text,
                    sessionId: sessionId,
                    currentApp: lastTargetApp || 'unknown',
                    lastAction: lastAction ? `${lastAction.action} to ${lastAction.app || 'local'}: "${lastAction.content}"` : 'none',
                    activity: isActiveDictation ? 'active_dictation' : (continuousMode ? 'continuous' : 'general'),
                    assistantName: assistantName.charAt(0).toUpperCase() + assistantName.slice(1).toLowerCase()
                };
                
                const response = await fetch('/api/parse-command', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(contextData)
                });
                const data = await response.json();
                console.log('üß† CLAUDE RESPONSE:', JSON.stringify(data, null, 2));
                
                // Claude ALWAYS returns a valid response now (no fallback)
                // Log if Claude corrected the transcription
                if (data.correctedText && data.correctedText !== text) {
                    console.log('üîß Speech corrected:', text, '‚Üí', data.correctedText);
                    addActivity(`üîß Heard "${text}" ‚Üí corrected to "${data.correctedText}"`, 'info');
                }
                
                return data;
            } catch (e) {
                console.error('Claude parse error:', e);
                // Return a safe default instead of null
                return {
                    action: 'clarify',
                    speak: 'Sorry, connection issue. Please try again.',
                    response: 'Error',
                    needsClarification: true
                };
            }
        }
        
        async function handleTranscript(text, skipRouting = false) {
            text = text.trim();
            
            // Basic pre-processing (Claude will do more sophisticated correction)
            // "right" is often misheard as "write"
            if (/^right\\s/i.test(text)) {
                text = text.replace(/^right\\s/i, 'write ');
                console.log('Corrected "right" to "write":', text);
            }
            // "cursor right something" ‚Üí "cursor write something"
            text = text.replace(/\\b(cursor|claude|chatgpt|terminal)\\s+right\\s/gi, '$1 write ');
            
            console.log('Voice:', text);
            
            let parsed = null;
            let claudeResult = null;
            
            // Try Claude first for intelligent parsing with context
            if (claudeAvailable && text.length > 2) {
                claudeResult = await parseWithClaude(text);
                
                if (claudeResult) {
                    // Use corrected text if Claude fixed transcription errors
                    const displayText = claudeResult.correctedText || text;
                    
                    // Show what user said in chat (use corrected version)
                    addChatMessage(displayText, 'user');
                    
                    // Check if Claude detected a stop command
                    if (claudeResult.isStopCommand) {
                        console.log('üß† Claude detected stop command');
                        return { isStop: true };  // Return to let caller handle stop
                    }
                    
                    // Handle "repeat" action
                    if (claudeResult.action === 'repeat' && lastAction) {
                        console.log('üîÑ Repeating last action:', lastAction);
                        addChatMessage('Repeating last action...', 'jarvis');
                        // Re-execute last action
                        parsed = {
                            originalText: text,
                            targetDevice: null,
                            targetApp: lastAction.appObj || null,
                            command: lastAction.content,
                            action: lastAction.action
                        };
                    }
                    // Check if Claude needs clarification
                    else if (claudeResult.needsClarification || claudeResult.action === 'clarify') {
                        const clarifyMessage = claudeResult.speak || 'Could you be more specific?';
                        
                        // Show Jarvis response in chat
                        addChatMessage(clarifyMessage, 'jarvis');
                        
                        // Speak the clarification
                        speakText(clarifyMessage);
                        
                        // Keep listening for the user's response
                        isActiveDictation = true;
                        document.getElementById('voice-status').textContent = 'Listening...';
                        addActivity(`ü§ñ ${claudeResult.response || 'Asking for clarification'}`, 'info');
                        
                        console.log('üß† Claude needs clarification:', clarifyMessage);
                        return; // Don't execute anything, wait for user response
                    }
                    // Claude has a response to speak (but still executing)
                    else if (claudeResult.speak && !claudeResult.needsClarification) {
                        addChatMessage(claudeResult.speak, 'jarvis');
                        speakText(claudeResult.speak);
                    }
                    
                    // Normal execution (if not already set by repeat)
                    if (!parsed && (claudeResult.targetApp || claudeResult.action)) {
                        const appId = (claudeResult.targetApp || '').toLowerCase();
                        const knownApp = knownApps[appId];
                        
                        parsed = {
                            originalText: text,
                            targetDevice: null,
                            targetApp: knownApp ? { id: appId, ...knownApp } : (appId ? { id: appId, name: claudeResult.targetApp, icon: 'ü§ñ' } : null),
                            command: claudeResult.content || text,
                            action: claudeResult.action || 'type'
                        };
                        
                        // Track this action for "repeat" and context
                        lastAction = {
                            action: parsed.action,
                            app: appId || null,
                            appObj: parsed.targetApp,
                            content: parsed.command,
                            timestamp: Date.now()
                        };
                        lastTargetApp = appId || lastTargetApp;
                        
                        console.log('üß† Claude:', claudeResult.response || `${parsed.action} ‚Üí ${appId || 'local'}`);
                        if (claudeResult.response) {
                            addActivity(`üß† ${claudeResult.response}`, 'info');
                            // Show brief confirmation in chat (but don't speak for normal commands)
                            if (!claudeResult.speak) {
                                addChatMessage(`‚úì ${claudeResult.response}`, 'jarvis');
                            }
                        }
                    }
                }
            } else {
                // Claude always returns a result now, but handle edge case
                addChatMessage(text, 'user');
                addChatMessage('Processing...', 'jarvis');
            }
            
            // Claude is the SOLE decision maker - no regex fallback
            // If parsed is still null (shouldn't happen), create minimal action
            if (!parsed) {
                console.log('‚ö†Ô∏è No Claude result - using text as-is');
                parsed = {
                    originalText: text,
                    targetDevice: null,
                    targetApp: null,
                    command: text,
                    action: 'type'
                };
            }
            
            // If targeting another device, route the command
            if (!skipRouting && parsed.targetDevice && parsed.targetDevice.id !== deviceId) {
                routeCommandToDevice(parsed.targetDevice, parsed.command, parsed.action);
                copyToClipboard(parsed.command); // Always copy to clipboard
                document.getElementById('transcript').textContent = `üì§ Sent to ${parsed.targetDevice.name}: "${parsed.command}"`;
                return;
            }
            
            // Handle browser actions (open_tab, open_url, search) - use Electron or route to desktop client
            if (!skipRouting && (parsed.action === 'open_tab' || parsed.action === 'open_url' || parsed.action === 'search')) {
                var actionLabel = parsed.action === 'open_tab' ? 'Opening new tab' : 
                                 parsed.action === 'open_url' ? 'Opening ' + parsed.command :
                                 'Searching: ' + parsed.command;
                
                // ELECTRON: Use built-in browser control
                if (isElectron && window.electronAPI?.executeCommand) {
                    (async () => {
                        try {
                            await window.electronAPI.executeCommand(parsed.action, parsed.command, null);
                            showLastCommand('üåê', actionLabel, parsed.command || 'new tab');
                            addActivity('üåê ' + actionLabel, 'success');
                            document.getElementById('transcript').textContent = 'üåê ' + actionLabel;
                        } catch (e) {
                            console.error('Browser action error:', e);
                        }
                    })();
                    return;
                }
                
                // FALLBACK: Route to desktop client
                const desktopClient = Object.values(devices).find(d => 
                    d.type === 'desktop_client' && d.id !== deviceId
                );
                
                if (desktopClient) {
                    socket.emit('route_command', {
                        fromDeviceId: deviceId,
                        toDeviceId: desktopClient.id,
                        command: parsed.command,
                        action: parsed.action,
                        targetApp: 'browser',
                        timestamp: new Date().toISOString()
                    });
                    
                    showLastCommand('üåê', actionLabel, parsed.command || 'new tab');
                    addActivity('üåê ' + actionLabel, 'success');
                    document.getElementById('transcript').textContent = 'üåê ' + actionLabel;
                    return;
                } else {
                    addActivity('‚ö†Ô∏è No desktop client connected for browser control', 'warning');
                }
            }
            
            // If targeting an app (cursor, vscode, etc), use Electron or route to desktop client
            if (!skipRouting && parsed.targetApp) {
                const appInfo = parsed.targetApp;
                
                // ELECTRON: Use built-in app control if running in Electron
                if (isElectron && window.electronAPI?.executeCommand) {
                    console.log('üñ•Ô∏è Using Electron to control:', appInfo.id);
                    
                    (async () => {
                        try {
                            const result = await window.electronAPI.executeCommand(
                                parsed.action || 'type_and_send',
                                parsed.command,
                                appInfo.id
                            );
                            
                            if (result.success) {
                                showLastCommand(appInfo.icon, `‚Üí ${appInfo.name}`, parsed.command);
                                addActivity(`‚úÖ Sent to ${appInfo.name}: "${parsed.command.substring(0, 40)}..."`, 'success');
                                document.getElementById('transcript').textContent = `‚úÖ ‚Üí ${appInfo.name}: "${parsed.command}"`;
                            } else {
                                addActivity(`‚ö†Ô∏è Failed to control ${appInfo.name}: ${result.error}`, 'warning');
                                // Copy to clipboard as fallback
                                copyToClipboard(parsed.command);
                                addActivity('üìã Copied to clipboard instead', 'info');
                            }
                        } catch (e) {
                            console.error('Electron command error:', e);
                            addActivity(`‚ö†Ô∏è Error: ${e.message}`, 'warning');
                            copyToClipboard(parsed.command);
                        }
                    })();
                    
                    return;
                }
                
                // FALLBACK: Route to desktop client if not in Electron
                console.log('Looking for desktop client. All devices:', Object.entries(devices).map(([id, d]) => ({id, type: d.type, name: d.name})));
                
                const desktopClient = Object.values(devices).find(d => 
                    d.type === 'desktop_client' && d.id !== deviceId
                );
                
                if (desktopClient) {
                    console.log('Routing command to:', desktopClient.id);
                    socket.emit('route_command', {
                        fromDeviceId: deviceId,
                        toDeviceId: desktopClient.id,
                        command: parsed.command,
                        action: parsed.action || 'type',
                        targetApp: appInfo.id,
                        timestamp: new Date().toISOString()
                    });
                    
                    copyToClipboard(parsed.command);
                    showLastCommand(appInfo.icon, `‚Üí ${appInfo.name} on ${desktopClient.name}`, parsed.command);
                    addActivity(`üì§ Sent to ${appInfo.name}: "${parsed.command.substring(0, 40)}..."`, 'success');
                    document.getElementById('transcript').textContent = `üì§ ‚Üí ${appInfo.name}: "${parsed.command}"`;
                    return;
                } else {
                    // No desktop client and not in Electron - copy to clipboard
                    addActivity(`‚ö†Ô∏è No way to control ${appInfo.name}. Use Electron app or run desktop client.`, 'warning');
                    copyToClipboard(parsed.command);
                    addActivity('üìã Copied to clipboard - paste manually', 'info');
                    document.getElementById('transcript').textContent = `üìã Copied: "${parsed.command}"`;
                }
                
                text = parsed.command;
            }
            
            // Apply formatting
            text = formatTranscript(text);
            
            document.getElementById('transcript').textContent = text;
            document.getElementById('transcript').classList.add('active');
            
            // Count words
            const wordCount = text.split(/\\s+/).filter(w => w).length;
            currentDevice.wordsTyped += wordCount;
            saveDevices();
            
            // Always copy to clipboard
            copyToClipboard(text);
            
            // Log activity
            if (autoType) {
                const targetInfo = parsed.targetApp ? ` ‚Üí ${parsed.targetApp.name}` : '';
                addActivity(`Typed${targetInfo}: "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}" (copied)`, 'success', wordCount);
            } else {
                addActivity(`Copied: "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}"`, 'info', wordCount);
            }
            
            // Emit to server
            socket.emit('transcript', { 
                deviceId, 
                text, 
                words: wordCount,
                targetApp: parsed.targetApp?.id,
                timestamp: new Date().toISOString()
            });
            
            renderDeviceList();
            renderAvailableDevices();
        }
        
        // Common misspellings and corrections
        const spellCheckDict = {
            'teh': 'the', 'thier': 'their', 'recieve': 'receive', 'wierd': 'weird',
            'occured': 'occurred', 'untill': 'until', 'seperate': 'separate',
            'definately': 'definitely', 'occassion': 'occasion', 'accomodate': 'accommodate',
            'occurence': 'occurrence', 'persistant': 'persistent', 'refered': 'referred',
            'apparant': 'apparent', 'calender': 'calendar', 'collegue': 'colleague',
            'concious': 'conscious', 'enviroment': 'environment', 'existance': 'existence',
            'fourty': 'forty', 'goverment': 'government', 'harrass': 'harass',
            'immediatly': 'immediately', 'independant': 'independent', 'knowlege': 'knowledge',
            'liason': 'liaison', 'millenium': 'millennium', 'neccessary': 'necessary',
            'noticable': 'noticeable', 'parliment': 'parliament', 'posession': 'possession',
            'prefered': 'preferred', 'publically': 'publicly', 'recomend': 'recommend',
            'reffering': 'referring', 'relevent': 'relevant', 'religous': 'religious',
            'repitition': 'repetition', 'resistence': 'resistance', 'responsability': 'responsibility',
            'succesful': 'successful', 'supercede': 'supersede', 'suprise': 'surprise',
            'tommorow': 'tomorrow', 'tounge': 'tongue', 'truely': 'truly',
            'unforseen': 'unforeseen', 'unfortunatly': 'unfortunately', 'wich': 'which',
            'writting': 'writing', 'your welcome': "you're welcome", 'alot': 'a lot',
            'shouldnt': "shouldn\'t", 'couldnt': "couldn\'t", 'wouldnt': "wouldn\'t",
            'dont': "don\'t", 'wont': "won\'t", 'cant': "can\'t", 'didnt': "didn\'t",
            'isnt': "isn\'t", 'wasnt': "wasn\'t", 'havent': "haven\'t", 'hasnt': "hasn\'t",
            'im': "I\'m", 'ive': "I\'ve", 'youre': "you\'re", 'theyre': "they\'re",
            'weve': "we\'ve", 'its a': "it\'s a", 'lets': "let\'s",
            // Common speech recognition errors
            'gonna': 'going to', 'wanna': 'want to', 'gotta': 'got to',
            'kinda': 'kind of', 'sorta': 'sort of', 'dunno': "don\'t know",
            'lemme': 'let me', 'gimme': 'give me', 'coulda': 'could have',
            'shoulda': 'should have', 'woulda': 'would have', 'musta': 'must have',
        };
        
        function spellCheck(text) {
            if (!spellCheckEnabled) return text;
            
            let corrected = text;
            let corrections = [];
            
            for (const [wrong, right] of Object.entries(spellCheckDict)) {
                const regex = new RegExp('\\\\b' + wrong + '\\\\b', 'gi');
                if (regex.test(corrected)) {
                    corrections.push({ from: wrong, to: right });
                    corrected = corrected.replace(regex, right);
                }
            }
            
            if (corrections.length > 0) {
                console.log('Spell corrections:', corrections);
                addActivity(`üìù Auto-corrected: ${corrections.map(c => c.from + ' ‚Üí ' + c.to).join(', ')}`, 'info');
            }
            
            return corrected;
        }
        
        function formatTranscript(text) {
            // Apply spell check first
            text = spellCheck(text);
            
            // Punctuation replacements
            const replacements = {
                'period': '.', 'comma': ',', 'question mark': '?',
                'exclamation mark': '!', 'exclamation point': '!',
                'colon': ':', 'semicolon': ';',
                'new line': String.fromCharCode(10), 'newline': String.fromCharCode(10), 
                'new paragraph': String.fromCharCode(10) + String.fromCharCode(10),
                'open quote': '"', 'close quote': '"', 'quote': '"',
                'open paren': '(', 'close paren': ')',
                'hyphen': '-', 'dash': '‚Äî'
            };
            
            for (const [word, symbol] of Object.entries(replacements)) {
                const regex = new RegExp('\\\\b' + word + '\\\\b', 'gi');
                text = text.replace(regex, symbol);
            }
            
            // Capitalize first letter
            text = text.charAt(0).toUpperCase() + text.slice(1);
            
            // Capitalize after periods
            text = text.replace(/([.!?]\\s*)(\\w)/g, (m, p1, p2) => p1 + p2.toUpperCase());
            
            return text.trim();
        }
        
        async function copyToClipboard(text) {
            try {
                await navigator.clipboard.writeText(text);
                // Try to simulate paste (note: this won't work in all contexts due to browser security)
                // The user can manually paste with Ctrl+V / Cmd+V
            } catch (err) {
                console.log('Clipboard write failed:', err);
            }
        }
        
        function startListening() {
            if (!recognition) {
                console.error('No recognition object');
                return;
            }
            if (isListening) {
                console.log('Already listening');
                return;
            }
            recognition.lang = currentDevice?.language || 'en-US';
            try {
                recognition.start();
                console.log('Recognition started');
            } catch (e) {
                console.log('Recognition start error:', e.name, e.message);
                if (e.name !== 'InvalidStateError') {
                    addActivity('‚ö†Ô∏è ' + e.message, 'warning');
                }
            }
        }
        
        function stopListening() {
            continuousMode = false;
            document.getElementById('toggle-continuous').classList.remove('active');
            
            // Stop Whisper if active
            if (useWhisper) {
                stopWhisperRecording();
            }
            
            // Stop Web Speech API if active
            if (recognition && isListening) {
            recognition.stop();
            }
            
            socket.emit('device_status', { deviceId, status: 'idle' });
        }
        
        async function toggleListening() {
            console.log('toggleListening called, isListening:', isListening, 'useWhisper:', useWhisper, 'useCloudWhisper:', useCloudWhisper, 'isElectron:', isElectron);
            
            if (isListening) {
                console.log('Stopping...');
                stopListening();
                return;
            }
            
            // ELECTRON or CLOUD WHISPER: Use OpenAI Whisper API
            if (isElectron || useWhisper || useCloudWhisper) {
                console.log('[WHISPER] Using', useCloudWhisper ? 'OpenAI Cloud' : 'Local', 'Whisper');
                
                const whisperAvailable = await checkWhisperService();
                if (whisperAvailable) {
                    useWhisper = true;
                    addActivity(useCloudWhisper ? '‚òÅÔ∏è Starting OpenAI Whisper...' : 'üé§ Starting Whisper...', 'info');
                    startWhisperRecording();
                } else {
                    if (useCloudWhisper) {
                        addActivity('‚ö†Ô∏è OpenAI API not configured. Add OPENAI_API_KEY in Render.', 'warning');
                    } else {
                        addActivity('‚ö†Ô∏è Whisper service not running. Restart the Cortona app.', 'warning');
                    }
                }
                return;
            }
            
            // BROWSER: Use Web Speech API
            if (!recognition) {
                console.error('No recognition object!');
                addActivity('‚ö†Ô∏è Speech recognition not available in this browser', 'warning');
                return;
            }
            
                try {
                console.log('Starting Web Speech API...');
                    recognition.lang = currentDevice?.language || 'en-US';
                    recognition.start();
                    addActivity('üé§ Starting microphone...', 'info');
                } catch (e) {
                    if (e.name === 'InvalidStateError') {
                        console.log('Recognition in invalid state, reinitializing...');
                        initSpeechRecognition();
                        setTimeout(() => {
                            try {
                                recognition.lang = currentDevice?.language || 'en-US';
                                recognition.start();
                                addActivity('üé§ Starting microphone...', 'info');
                            } catch (e2) {
                                addActivity('‚ö†Ô∏è Could not start microphone: ' + e2.message, 'warning');
                            }
                        }, 100);
                    } else {
                        addActivity('‚ö†Ô∏è Could not start microphone: ' + e.message, 'warning');
                }
            }
        }
        
        // ============================================================
        // UI UPDATES
        // ============================================================
        
        // Track if we've initialized to avoid "Starting" flicker
        let hasInitialized = false;
        
        function updateUI() {
            // Get elements with null safety
            const micButton = document.getElementById('mic-button');
            const voiceStatus = document.getElementById('voice-status');
            const voiceHint = document.getElementById('voice-hint');
            const wakeWordSpan = document.getElementById('current-wake-word');
            
            // Guard: don't proceed if critical elements missing
            if (!micButton || !voiceStatus || !voiceHint) {
                console.warn('updateUI: Required elements not found');
                return;
            }
            
            // During restart, keep UI stable - don't flicker between states
            if (isRestarting && alwaysListen && hasInitialized) {
                // Keep showing stable "Standby" state during restart
                micButton.classList.add('listening');
                micButton.innerHTML = 'ON';
                voiceStatus.textContent = 'Standby';
                // Don't update other elements - prevent flicker
                return;
            }
            
            if (isListening) {
                hasInitialized = true; // Mark as initialized once we're listening
                micButton.classList.add('listening');
                if (alwaysListen && !isActiveDictation) {
                    // In always-listen mode, waiting for wake word
                    micButton.innerHTML = 'ON';
                    voiceStatus.textContent = 'Standby';
                    voiceHint.innerHTML = `Say "<strong>${currentDevice?.wakeWord || 'hey computer'}</strong>" to activate`;
                } else if (isActiveDictation) {
                    // Active dictation after wake word
                    micButton.innerHTML = 'REC';
                    voiceStatus.textContent = 'Listening...';
                    voiceHint.innerHTML = 'Speak your command. Say "<strong>stop</strong>" when done.';
                } else {
                    // Manual recording mode
                    micButton.innerHTML = 'REC';
                    voiceStatus.textContent = 'Recording';
                    voiceHint.innerHTML = continuousMode ? 'Continuous mode active' : 'Speak now. Say "stop" or click to end.';
                }
            } else {
                // When not listening...
                if (alwaysListen && hasInitialized) {
                    // In always-listen mode after initialization - keep showing Standby (mic is just restarting)
                    // Don't change the UI - it will update when recognition restarts
                    micButton.classList.add('listening');
                    micButton.innerHTML = 'ON';
                    voiceStatus.textContent = 'Standby';
                    voiceHint.innerHTML = `Say "<strong>${currentDevice?.wakeWord || 'hey computer'}</strong>" to activate`;
                } else if (alwaysListen && !hasInitialized) {
                    // First time starting always-listen mode
                micButton.classList.remove('listening');
                micButton.innerHTML = 'MIC';
                    voiceStatus.textContent = 'Starting';
                    voiceHint.innerHTML = 'Initializing microphone...';
                } else {
                    // Not in always-listen mode
                    micButton.classList.remove('listening');
                    micButton.innerHTML = 'MIC';
                    voiceStatus.textContent = 'Off';
                    voiceHint.innerHTML = 'Click to start listening';
                    hasInitialized = false; // Reset when fully stopped
                }
            }
            
            if (wakeWordSpan) {
                wakeWordSpan.textContent = `"${currentDevice?.wakeWord || 'hey computer'}"`;
            }
            
            // Update settings header to show which device is being edited
            const editingLabel = document.getElementById('editing-device-name');
            if (editingLabel) {
                editingLabel.textContent = currentDevice?.name || 'This Device';
            }
            
            // Update settings inputs (with null safety)
            const nameInput = document.getElementById('device-name-input');
            const wakeWordInput = document.getElementById('wake-word-input');
            const langSelect = document.getElementById('language-select');
            const sensitivitySlider = document.getElementById('sensitivity-slider');
            const sensitivityLabel = document.getElementById('sensitivity-label');
            const alwaysListenToggle = document.getElementById('toggle-always-listen');
            const badgeAlways = document.getElementById('badge-always');
            const badgeContinuous = document.getElementById('badge-continuous');
            
            // Only update inputs if they're NOT focused (to prevent overwriting user's typing)
            const activeElement = document.activeElement;
            if (nameInput && activeElement !== nameInput) nameInput.value = currentDevice?.name || '';
            if (wakeWordInput && activeElement !== wakeWordInput) wakeWordInput.value = currentDevice?.wakeWord || '';
            if (langSelect && activeElement !== langSelect) langSelect.value = currentDevice?.language || 'en-US';
            if (sensitivitySlider) sensitivitySlider.value = sensitivity;
            if (sensitivityLabel) sensitivityLabel.textContent = sensitivityLabels[sensitivity];
            if (alwaysListenToggle) alwaysListenToggle.classList.toggle('active', alwaysListen);
            if (badgeAlways) badgeAlways.style.display = alwaysListen ? 'inline-block' : 'none';
            if (badgeContinuous) badgeContinuous.style.display = continuousMode ? 'inline-block' : 'none';
        }
        
        let editingDeviceId = null;
        
        // Format relative time (e.g., "just now", "2 min ago")
        function formatLastSeen(isoString) {
            if (!isoString) return '';
            const date = new Date(isoString);
            const now = new Date();
            const seconds = Math.floor((now - date) / 1000);
            
            if (seconds < 10) return 'just now';
            if (seconds < 60) return seconds + 's ago';
            
            const minutes = Math.floor(seconds / 60);
            if (minutes < 60) return minutes + ' min ago';
            
            const hours = Math.floor(minutes / 60);
            if (hours < 24) return hours + 'h ago';
            
            const days = Math.floor(hours / 24);
            return days + 'd ago';
        }
        
        function renderDeviceList() {
            const listEl = document.getElementById('device-list');
            if (!listEl) return;
            
            // Get all devices, prioritize current device first
            const allDevices = Object.values(devices);
            const thisDevice = allDevices.find(d => d.id === deviceId);
            const otherDevices = allDevices.filter(d => d.id !== deviceId && d.type !== 'desktop_client');
            
            let html = '';
            
            // This device first (highlighted)
            if (thisDevice) {
                html += `
                    <div class="device-item" onclick="openDeviceEditor('${thisDevice.id}')" style="cursor: pointer; padding: 12px; background: rgba(0,245,212,0.15); border-radius: 10px; border: 2px solid var(--accent); margin-bottom: 8px; transition: transform 0.1s;">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div style="display: flex; align-items: center; gap: 8px;">
                                <span style="font-size: 20px;">${thisDevice.icon || 'üíª'}</span>
                                <strong>${thisDevice.name || 'This Device'}</strong>
                            </div>
                            <span style="font-size: 9px; background: var(--success); color: white; padding: 2px 8px; border-radius: 10px;">THIS DEVICE</span>
                        </div>
                        <div style="font-size: 12px; color: var(--accent); margin-top: 6px; font-family: monospace;">
                            Wake: "${thisDevice.wakeWord || 'computer'}"
                        </div>
                        <div style="font-size: 10px; color: var(--text-muted); margin-top: 4px;">Click to edit</div>
                    </div>
                `;
            }
            
            // Other connected devices
            otherDevices.forEach(d => {
                const isOnline = d.online !== false;
                const lastSeenText = d.lastSeen ? formatLastSeen(d.lastSeen) : '';
                const statusText = isOnline ? (lastSeenText ? 'Active ' + lastSeenText : 'ONLINE') : 'OFFLINE';
                
                html += `
                    <div class="device-item" onclick="openDeviceEditor('${d.id}')" style="cursor: pointer; padding: 10px; background: var(--bg-secondary); border-radius: 8px; margin-bottom: 6px; opacity: ${isOnline ? 1 : 0.5}; transition: transform 0.1s;">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div style="display: flex; align-items: center; gap: 8px;">
                                <span style="font-size: 18px;">${d.icon || 'üíª'}</span>
                                <span>${d.name || 'Unknown'}</span>
                            </div>
                            <span style="font-size: 8px; background: ${isOnline ? 'var(--success)' : 'var(--text-muted)'}; color: white; padding: 2px 6px; border-radius: 8px;">
                                ${statusText}
                            </span>
                        </div>
                        <div style="font-size: 11px; color: var(--text-muted); margin-top: 4px; font-family: monospace;">
                            Wake: "${d.wakeWord || 'unknown'}"
                        </div>
                    </div>
                `;
            });
            
            // If no other devices
            if (otherDevices.length === 0 && thisDevice) {
                html += `<div style="color: var(--text-muted); font-size: 12px; padding: 8px; text-align: center;">No other devices connected</div>`;
            }
            
            listEl.innerHTML = html;
        }
        
        // Update lastSeen display every 30 seconds
        setInterval(renderDeviceList, 30000);
        
        function openDeviceEditor(id) {
            // Close any existing modal first
            closeDeviceEditor();
            
            editingDeviceId = id;
            const device = devices[id];
            if (!device) return;
            
            const isThisDevice = id === deviceId;
            
            const modal = document.createElement('div');
            modal.id = 'device-editor-modal';
            modal.style.cssText = 'position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(0,0,0,0.8); display: flex; align-items: center; justify-content: center; z-index: 10000;';
            
            let modalHTML = '<div id="device-editor-content" style="background: var(--bg-secondary); border-radius: 16px; padding: 24px; width: 90%; max-width: 400px; border: 1px solid var(--border);">';
            modalHTML += '<div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 16px;">';
            modalHTML += '<h3 style="margin: 0; display: flex; align-items: center; gap: 8px;">';
            modalHTML += '<span id="editor-header-icon" style="font-size: 24px;">' + (device.icon || 'üíª') + '</span> Edit Device</h3>';
            modalHTML += '<button id="close-editor-btn" style="background: none; border: none; color: var(--text-muted); font-size: 24px; cursor: pointer; padding: 4px 8px;">&times;</button></div>';
            
            // Clear status indicator
            if (isThisDevice) {
                modalHTML += '<div style="background: rgba(0,245,212,0.15); border: 1px solid var(--accent); border-radius: 8px; padding: 10px; margin-bottom: 16px; font-size: 13px; color: var(--accent); display: flex; align-items: center; gap: 8px;">';
                modalHTML += '<span style="font-size: 16px;">‚úì</span> <strong>This is YOUR current device</strong></div>';
            } else {
                modalHTML += '<div style="background: rgba(255,165,0,0.15); border: 1px solid orange; border-radius: 8px; padding: 10px; margin-bottom: 16px; font-size: 13px; color: orange; display: flex; align-items: center; gap: 8px;">';
                modalHTML += '<span style="font-size: 16px;">üì°</span> <strong>Editing REMOTE device:</strong> ' + (device.name || 'Unknown') + '</div>';
            }
            
            modalHTML += '<div style="margin-bottom: 16px;">';
            modalHTML += '<label style="display: block; margin-bottom: 6px; font-size: 13px; color: var(--text-muted);">Device Name <span style="color: var(--text-muted); font-size: 11px;">(used for cross-device commands)</span></label>';
            modalHTML += '<input type="text" id="edit-device-name" value="' + (device.name || '').replace(/"/g, '&quot;') + '" style="width: 100%; padding: 12px; border-radius: 8px; border: 1px solid var(--border); background: var(--bg-primary); color: var(--text-primary); font-size: 15px; box-sizing: border-box;" autocomplete="off" spellcheck="false">';
            modalHTML += '</div>';
            
            modalHTML += '<div style="margin-bottom: 16px;">';
            modalHTML += '<label style="display: block; margin-bottom: 6px; font-size: 13px; color: var(--text-muted);">Wake Word <span style="color: var(--text-muted); font-size: 11px;">(activates this device only)</span></label>';
            modalHTML += '<input type="text" id="edit-device-wake" value="' + (device.wakeWord || '').replace(/"/g, '&quot;') + '" style="width: 100%; padding: 12px; border-radius: 8px; border: 1px solid var(--border); background: var(--bg-primary); color: var(--text-primary); font-size: 15px; box-sizing: border-box;" autocomplete="off" spellcheck="false">';
            modalHTML += '<div style="font-size: 11px; color: var(--text-muted); margin-top: 4px;">Say this word to activate listening on this device</div>';
            modalHTML += '</div>';
            
            modalHTML += '<div style="margin-bottom: 20px;">';
            modalHTML += '<label style="display: block; margin-bottom: 6px; font-size: 13px; color: var(--text-muted);">Icon</label>';
            modalHTML += '<div style="display: flex; gap: 8px; flex-wrap: wrap;">';
            var icons = ['üíª', 'üñ•Ô∏è', 'üì±', '‚å®Ô∏è', 'üéß', 'üé§', 'üñ±Ô∏è', 'üì∫'];
            for (var i = 0; i < icons.length; i++) {
                var icon = icons[i];
                var isSelected = device.icon === icon;
                var btnStyle = 'padding: 8px 12px; border-radius: 8px; border: 2px solid ' + (isSelected ? 'var(--accent)' : 'var(--border)') + '; background: ' + (isSelected ? 'rgba(0,245,212,0.1)' : 'var(--bg-primary)') + '; cursor: pointer; font-size: 18px;';
                modalHTML += '<button data-icon="' + icon + '" style="' + btnStyle + '">' + icon + '</button>';
            }
            modalHTML += '</div></div>';
            
            modalHTML += '<div style="display: flex; gap: 12px;">';
            modalHTML += '<button onclick="saveDeviceEdit()" style="flex: 1; padding: 12px; border-radius: 8px; border: none; background: var(--accent); color: var(--bg-primary); font-weight: 600; cursor: pointer;">Save Changes</button>';
            modalHTML += '<button onclick="closeDeviceEditor()" style="padding: 12px 20px; border-radius: 8px; border: 1px solid var(--border); background: transparent; color: var(--text-primary); cursor: pointer;">Cancel</button>';
            modalHTML += '</div></div>';
            
            modal.innerHTML = modalHTML;
            document.body.appendChild(modal);
            
            // Set up event listeners after modal is in DOM
            var closeBtn = document.getElementById('close-editor-btn');
            if (closeBtn) {
                closeBtn.onclick = function(e) {
                    e.stopPropagation();
                    closeDeviceEditor();
                };
            }
            
            // Prevent clicks inside the modal content from closing it
            var content = document.getElementById('device-editor-content');
            if (content) {
                content.onclick = function(e) {
                    e.stopPropagation();
                    // Handle icon button clicks
                    if (e.target.dataset && e.target.dataset.icon) {
                        selectDeviceIcon(e.target.dataset.icon);
                    }
                };
            }
            
            // Close only when clicking the backdrop
            modal.onclick = function(e) {
                if (e.target === modal) {
                    closeDeviceEditor();
                }
            };
            
            // Focus the name input
            setTimeout(function() {
                var nameInput = document.getElementById('edit-device-name');
                if (nameInput) nameInput.focus();
            }, 100);
        }
        
        function selectDeviceIcon(icon) {
            if (editingDeviceId && devices[editingDeviceId]) {
                // Update the icon in memory
                devices[editingDeviceId].icon = icon;
                
                // Update just the icon buttons visually (no re-render)
                var buttons = document.querySelectorAll('#device-editor-modal button[data-icon]');
                buttons.forEach(function(btn) {
                    var btnIcon = btn.dataset.icon;
                    var isSelected = btnIcon === icon;
                    btn.style.borderColor = isSelected ? 'var(--accent)' : 'var(--border)';
                    btn.style.background = isSelected ? 'rgba(0,245,212,0.1)' : 'var(--bg-primary)';
                });
                
                // Update the icon in the header
                var headerIcon = document.getElementById('editor-header-icon');
                if (headerIcon) headerIcon.textContent = icon;
            }
        }
        
        function saveDeviceEdit() {
            if (!editingDeviceId) return;
            
            const name = document.getElementById('edit-device-name').value.trim();
            const wakeWord = document.getElementById('edit-device-wake').value.trim().toLowerCase();
            
            if (!name || !wakeWord) {
                alert('Please fill in all fields');
                return;
            }
            
            const device = devices[editingDeviceId];
            device.name = name;
            device.wakeWord = wakeWord;
            
            // If editing current device, update currentDevice too
            if (editingDeviceId === deviceId) {
                currentDevice.name = name;
                currentDevice.wakeWord = wakeWord;
                currentDevice.icon = device.icon;
                saveDevices(); // Save to localStorage
            }
            
            // Sync to server so other devices see the change
            socket.emit('device_update', {
                deviceId: editingDeviceId,
                settings: {
                    name: device.name,
                    wakeWord: device.wakeWord,
                    icon: device.icon
                }
            });
            
            closeDeviceEditor();
            renderDeviceList();
            addActivity('Device updated: ' + name, 'success');
        }
        
        function closeDeviceEditor() {
            const modal = document.getElementById('device-editor-modal');
            if (modal) modal.remove();
            editingDeviceId = null;
        }
        
        function addActivity(message, type = 'info', words = 0) {
            const time = new Date().toLocaleTimeString();
            activityLog.unshift({ message, type, time, words });
            activityLog = activityLog.slice(0, 50); // Keep last 50
            renderActivityLog();
        }
        
        function renderActivityLog() {
            const listEl = document.getElementById('activity-list');
            
            if (activityLog.length === 0) {
                listEl.innerHTML = `
                    <div class="empty-state">
                        <div class="icon">üìù</div>
                        <h3>No activity yet</h3>
                        <p>Start speaking to see your transcripts here</p>
                    </div>
                `;
                return;
            }
            
            const icons = { success: '‚úÖ', info: '‚ÑπÔ∏è', warning: '‚ö†Ô∏è' };
            
            listEl.innerHTML = activityLog.map(a => `
                <div class="activity-item">
                    <div class="activity-icon ${a.type}">${icons[a.type] || '‚ÑπÔ∏è'}</div>
                    <div class="activity-content">
                        <p>${a.message}</p>
                        <span class="time">${a.time}${a.words ? ` ‚Ä¢ ${a.words} words` : ''}</span>
                    </div>
                </div>
            `).join('');
        }
        
        // ============================================================
        // TRANSCRIPT HISTORY
        // ============================================================
        
        function addToTranscriptHistory(text, type = 'command') {
            const entry = {
                id: Date.now(),
                text: text,
                type: type, // 'command', 'wake', 'routed'
                time: new Date(),
                device: currentDevice?.name || 'Unknown'
            };
            transcriptHistory.push(entry);
            updateTranscriptCount();
        }
        
        function updateTranscriptCount() {
            const countEl = document.getElementById('transcript-count');
            if (transcriptHistory.length > 0) {
                countEl.textContent = transcriptHistory.length;
                countEl.style.display = 'inline';
            } else {
                countEl.style.display = 'none';
            }
        }
        
        function openTranscriptHistory() {
            renderTranscriptHistory();
            document.getElementById('transcript-history-modal').classList.add('active');
        }
        
        function closeTranscriptHistory() {
            document.getElementById('transcript-history-modal').classList.remove('active');
        }
        
        function renderTranscriptHistory() {
            const listEl = document.getElementById('transcript-history-list');
            const infoEl = document.getElementById('transcript-session-info');
            
            // Update session info
            const elapsed = Math.floor((new Date() - sessionStartTime) / 1000 / 60);
            if (elapsed < 1) {
                infoEl.textContent = 'Session started just now';
            } else if (elapsed < 60) {
                infoEl.textContent = 'Session: ' + elapsed + ' min ‚Ä¢ ' + transcriptHistory.length + ' transcripts';
            } else {
                const hours = Math.floor(elapsed / 60);
                const mins = elapsed % 60;
                infoEl.textContent = 'Session: ' + hours + 'h ' + mins + 'm ‚Ä¢ ' + transcriptHistory.length + ' transcripts';
            }
            
            if (transcriptHistory.length === 0) {
                listEl.innerHTML = '<p style="color: var(--text-muted); text-align: center; padding: 40px;">No transcripts yet. Start speaking to record your session.</p>';
                return;
            }
            
            // Render in reverse chronological order (newest first)
            const typeIcons = {
                command: 'üí¨',
                wake: 'üéØ',
                routed: 'üì§',
                stop: 'üõë'
            };
            
            const typeLabels = {
                command: 'Command',
                wake: 'Wake Word',
                routed: 'Routed',
                stop: 'Stopped'
            };
            
            listEl.innerHTML = transcriptHistory.slice().reverse().map(function(entry) {
                const timeStr = entry.time.toLocaleTimeString();
                var icon = typeIcons[entry.type] || 'üí¨';
                var label = typeLabels[entry.type] || 'Transcript';
                
                return '<div style="background: var(--bg-secondary); border-radius: 12px; padding: 14px 16px; border-left: 3px solid ' + (entry.type === 'wake' ? 'var(--accent)' : entry.type === 'routed' ? '#a855f7' : 'var(--border)') + ';">' +
                    '<div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 6px;">' +
                        '<span style="font-size: 12px; color: var(--text-muted);">' + icon + ' ' + label + '</span>' +
                        '<span style="font-size: 11px; color: var(--text-muted);">' + timeStr + '</span>' +
                    '</div>' +
                    '<p style="font-size: 15px; line-height: 1.5; margin: 0; word-break: break-word;">' + escapeHtml(entry.text) + '</p>' +
                '</div>';
            }).join('');
        }
        
        function clearTranscriptHistory() {
            transcriptHistory = [];
            updateTranscriptCount();
            renderTranscriptHistory();
            addActivity('Session transcripts cleared', 'info');
        }
        
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        // Add click listener for transcript header
        document.getElementById('transcript-header').addEventListener('click', openTranscriptHistory);
        
        // ============================================================
        // DEVICE MANAGEMENT
        // ============================================================
        
        function deleteDevice(id) {
            if (id === deviceId) {
                addActivity('Cannot delete this browser device', 'warning');
                return;
            }
            
            const device = devices[id];
            const name = device?.name || 'Unknown';
            
            if (confirm(`Delete device "${name}"? This cannot be undone.`)) {
                delete devices[id];
                saveDevices();
                socket.emit('device_delete', { deviceId: id });
                renderDeviceList();
                renderAvailableDevices();
                addActivity(`Deleted device: ${name}`, 'info');
            }
        }
        
        function selectDevice(id) {
            if (devices[id]) {
                currentDevice = devices[id];
                
                // Load this device's settings into the UI
                alwaysListen = currentDevice.alwaysListen || false;
                continuousMode = currentDevice.continuous || false;
                autoType = currentDevice.autoType ?? true;
                spellCheckEnabled = currentDevice.spellCheck ?? true;
                sensitivity = currentDevice.sensitivity || 3;
                
                if (recognition) {
                    recognition.lang = currentDevice.language || 'en-US';
                }
                
                // Update all toggle states
                document.getElementById('toggle-always-listen').classList.toggle('active', alwaysListen);
                document.getElementById('toggle-continuous').classList.toggle('active', continuousMode);
                document.getElementById('toggle-autotype').classList.toggle('active', autoType);
                document.getElementById('toggle-spellcheck').classList.toggle('active', spellCheckEnabled);
                
                updateUI();
                renderDeviceList();
                
                // Show which device is selected
                addActivity(`Selected device: ${currentDevice.name || 'Unnamed'}`, 'info');
            }
        }
        
        function updateDeviceSetting(setting, value) {
            if (!currentDevice) {
                addActivity('No device selected', 'warning');
                return;
            }
            
            if (setting === 'wakeWord') {
                value = value.toLowerCase().trim();
            }
            
            currentDevice[setting] = value;
            devices[currentDevice.id] = currentDevice;
            saveDevices();
            
            if (setting === 'language' && recognition) {
                recognition.lang = value;
            }
            
            updateUI();
            renderDeviceList();
            addActivity(`Updated ${setting} to "${value}"`, 'info');
            
            // Sync to server
            socket.emit('device_update', { deviceId: currentDevice.id, settings: currentDevice });
        }
        
        async function toggleAlwaysListen() {
            console.log('toggleAlwaysListen called, current:', alwaysListen, 'micPermission:', micPermission);
            
            // If enabling, check permission first
            if (!alwaysListen && micPermission !== 'granted') {
                console.log('Requesting mic permission...');
                const granted = await requestMicPermission();
                if (!granted) {
                    console.log('Mic permission denied');
                    return;
                }
            }
            
            alwaysListen = !alwaysListen;
            console.log('alwaysListen now:', alwaysListen);
            document.getElementById('toggle-always-listen').classList.toggle('active', alwaysListen);
            currentDevice.alwaysListen = alwaysListen;
            saveDevices();
            
            if (alwaysListen) {
                addActivity('Wake word listening enabled', 'success');
                startListening();
            } else {
                addActivity('Wake word listening disabled', 'info');
                if (isListening && !continuousMode) {
                    stopListening();
                }
            }
            updateUI();
        }
        
        async function toggleContinuous() {
            // If enabling, check permission first
            if (!continuousMode && micPermission !== 'granted') {
                const granted = await requestMicPermission();
                if (!granted) return;
            }
            
            continuousMode = !continuousMode;
            document.getElementById('toggle-continuous').classList.toggle('active', continuousMode);
            currentDevice.continuous = continuousMode;
            saveDevices();
            
            if (continuousMode && !isListening) {
                startListening();
            }
            
            addActivity(continuousMode ? 'Continuous dictation enabled' : 'Continuous dictation disabled', 'info');
        }
        
        function toggleAutoType() {
            autoType = !autoType;
            document.getElementById('toggle-autotype').classList.toggle('active', autoType);
            currentDevice.autoType = autoType;
            saveDevices();
            addActivity(autoType ? 'Auto-type enabled' : 'Auto-type disabled', 'info');
        }
        
        function updateSensitivity(value) {
            sensitivity = parseInt(value);
            currentDevice.sensitivity = sensitivity;
            saveDevices();
            document.getElementById('sensitivity-label').textContent = sensitivityLabels[sensitivity];
            addActivity(`Wake word sensitivity set to: ${sensitivityLabels[sensitivity]}`, 'info');
        }
        
        function toggleSpellCheck() {
            spellCheckEnabled = !spellCheckEnabled;
            document.getElementById('toggle-spellcheck').classList.toggle('active', spellCheckEnabled);
            currentDevice.spellCheck = spellCheckEnabled;
            saveDevices();
            addActivity(spellCheckEnabled ? '‚úì Spell check enabled' : 'Spell check disabled', 'info');
        }
        
        // ============================================================
        // MODAL HANDLERS
        // ============================================================
        
        function openAddDeviceModal() {
            document.getElementById('add-device-modal').classList.add('active');
            document.getElementById('new-device-name').focus();
        }
        
        function closeAddDeviceModal() {
            document.getElementById('add-device-modal').classList.remove('active');
            document.getElementById('new-device-name').value = '';
            document.getElementById('new-device-wake').value = '';
        }
        
        function addDevice() {
            const name = document.getElementById('new-device-name').value.trim();
            const wakeWord = document.getElementById('new-device-wake').value.trim().toLowerCase();
            const icon = document.getElementById('new-device-icon').value;
            
            if (!name) {
                alert('Please enter a device name');
                return;
            }
            
            const newId = 'device_' + Math.random().toString(36).substr(2, 9);
            devices[newId] = {
                id: newId,
                name,
                wakeWord: wakeWord || 'hey computer',
                icon,
                language: 'en-US',
                wordsTyped: 0,
                sessions: 0,
                continuous: false,
                autoType: true
            };
            
            saveDevices();
            renderDeviceList();
            closeAddDeviceModal();
            addActivity(`Added new device: ${name}`, 'success');
            
            socket.emit('device_add', devices[newId]);
        }
        
        // ============================================================
        // SOCKET EVENTS
        // ============================================================
        
        socket.on('connect', () => {
            console.log('Connected to server');
            // Send full device info when joining
            socket.emit('dashboard_join', { 
                deviceId: deviceId,
                device: {
                    id: deviceId,
                    name: currentDevice.name,
                    wakeWord: currentDevice.wakeWord,
                    icon: currentDevice.icon,
                    type: 'browser'
                }
            });
            
            // Send heartbeat every 30 seconds to keep lastSeen updated
            setInterval(function() {
                socket.emit('heartbeat', { deviceId: deviceId });
            }, 30000);
        });
        
        socket.on('devices_update', (data) => {
            if (data.devices) {
                for (const [id, device] of Object.entries(data.devices)) {
                    // Update or add the device
                    devices[id] = { ...devices[id], ...device };
                    
                    // If this is OUR device and settings were changed remotely, update currentDevice and save
                    if (id === deviceId) {
                        var wasChanged = false;
                        if (device.name && device.name !== currentDevice.name) {
                            currentDevice.name = device.name;
                            wasChanged = true;
                        }
                        if (device.wakeWord && device.wakeWord !== currentDevice.wakeWord) {
                            currentDevice.wakeWord = device.wakeWord;
                            wasChanged = true;
                        }
                        if (device.icon && device.icon !== currentDevice.icon) {
                            currentDevice.icon = device.icon;
                            wasChanged = true;
                        }
                        if (wasChanged) {
                            console.log('Device settings updated remotely:', currentDevice.name, currentDevice.wakeWord);
                            saveDevices();
                            updateUI();
                        }
                    }
                }
                renderDeviceList();
                renderAvailableDevices();
                
                // Debug: log connected desktop clients
                const desktopClients = Object.values(devices).filter(d => d.type === 'desktop_client');
                if (desktopClients.length > 0) {
                    console.log('Desktop clients available:', desktopClients.map(d => d.name));
                }
            }
        });
        
        // Handle incoming routed commands from other devices
        socket.on('command_received', (data) => {
            console.log('Received routed command:', data);
            handleRoutedCommand(data);
        });
        
        // Handle device online/offline updates
        socket.on('device_online', (data) => {
            const id = data.deviceId;
            if (data.device) {
                // New or updated device info
                devices[id] = { ...devices[id], ...data.device, online: true };
            } else if (devices[id]) {
                devices[id].online = true;
            }
            renderDeviceList();
            renderAvailableDevices();
            console.log('Device online:', data.device?.name || id);
        });
        
        socket.on('device_offline', (data) => {
            if (devices[data.deviceId]) {
                devices[data.deviceId].online = false;
                devices[data.deviceId].lastSeen = new Date().toISOString();
                renderDeviceList();
                renderAvailableDevices();
            }
        });
        
        socket.on('device_heartbeat', (data) => {
            if (devices[data.deviceId]) {
                devices[data.deviceId].lastSeen = data.lastSeen;
                devices[data.deviceId].online = true;
                renderDeviceList();
            }
        });
        
        // ============================================================
        // INITIALIZATION
        // ============================================================
        
        // Initial render
        updateUI();
        renderDeviceList();
        renderActivityLog();
        renderAvailableDevices();
        
        // Restore settings
        alwaysListen = currentDevice?.alwaysListen || false;
        continuousMode = currentDevice?.continuous || false;
        autoType = currentDevice?.autoType ?? true;
        spellCheckEnabled = currentDevice?.spellCheck ?? true;
        sensitivity = currentDevice?.sensitivity || 3;
        
        document.getElementById('toggle-always-listen').classList.toggle('active', alwaysListen);
        document.getElementById('toggle-continuous').classList.toggle('active', continuousMode);
        document.getElementById('toggle-autotype').classList.toggle('active', autoType);
        document.getElementById('toggle-spellcheck').classList.toggle('active', spellCheckEnabled);
        document.getElementById('sensitivity-slider').value = sensitivity;
        document.getElementById('sensitivity-label').textContent = sensitivityLabels[sensitivity];
        
        // Close modal on escape
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape') closeAddDeviceModal();
        });
        
        // Close modal on overlay click
        document.getElementById('add-device-modal').addEventListener('click', (e) => {
            if (e.target.id === 'add-device-modal') closeAddDeviceModal();
        });
        
        // Auto-start listening if always-listen or continuous mode is enabled
        if (alwaysListen || continuousMode) {
            setTimeout(() => {
                addActivity('üöÄ Auto-starting voice recognition...', 'info');
                startListening();
            }, 1000);
        }
    